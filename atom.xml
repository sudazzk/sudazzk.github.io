<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JuTzungKuei</title>
  
  <subtitle>zzk&#39;s homepage</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.zhuzongkui.top/"/>
  <updated>2019-09-07T06:15:01.677Z</updated>
  <id>http://www.zhuzongkui.top/</id>
  
  <author>
    <name>Zongkui Zhu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Anaconda 使用教程</title>
    <link href="http://www.zhuzongkui.top/2019/09/07/anaconda/"/>
    <id>http://www.zhuzongkui.top/2019/09/07/anaconda/</id>
    <published>2019-09-07T04:39:00.000Z</published>
    <updated>2019-09-07T06:15:01.677Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h1><ul><li>官网：<a href="https://www.anaconda.com/" target="_blank" rel="noopener">https://www.anaconda.com/</a></li><li>下载安装包：<a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">https://www.anaconda.com/distribution/</a></li><li><a href="https://mirror.tuna.tsinghua.edu.cn/help/anaconda/" target="_blank" rel="noopener">清华镜像</a></li><li><a href="https://docs.conda.io/en/latest/miniconda.html" target="_blank" rel="noopener">Miniconda</a></li><li><a href="https://blog.csdn.net/ITLearnHall/article/details/81708148" target="_blank" rel="noopener">Anaconda详细安装及使用教程</a></li></ul><h1 id="一、Anaconda3-安装与卸载"><a href="#一、Anaconda3-安装与卸载" class="headerlink" title="一、Anaconda3 安装与卸载"></a>一、Anaconda3 安装与卸载</h1><h2 id="Linux-安装"><a href="#Linux-安装" class="headerlink" title="Linux 安装"></a>Linux 安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 依次输入以下命令</span><br><span class="line">wget https://repo.continuum.io/archive/Anaconda3-5.1.0-Linux-x86_64.sh  # 等待下载完成</span><br><span class="line"></span><br><span class="line">bash Anaconda3-5.1.0-Linux-x86_64.sh    # 调用shell程序</span><br><span class="line">ENTER   # 按回车键</span><br><span class="line">q       # 输入q，不用按回车键</span><br><span class="line">yes     # 输入yes，按回车键</span><br><span class="line">ENTER   # 等待安装完成</span><br><span class="line">yes     # 输入yes，添加环境变量到当前用户目录下</span><br><span class="line"># 下一步不用输入 yes，直接重新打开 Linux 终端，当前用户根的目录下会有一个 anaconda3/ 目录</span><br><span class="line"></span><br><span class="line"># 测试是否已安装好 Anaconda 3，输入 python 按回车键会显示如下信息：</span><br><span class="line">Python 3.6.4 |Anaconda, Inc.| (default, Jan 16 2018, 18:10:19)</span><br><span class="line">[GCC 7.2.0] on linux</span><br><span class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line"># 再输入 exit()，按回车键退出 python 环境</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ~/anaconda3  # 卸载anaconda</span><br></pre></td></tr></table></figure><h2 id="Windows-安装"><a href="#Windows-安装" class="headerlink" title="Windows 安装"></a>Windows 安装</h2><ul><li>安装exe文件时，注意点击添加环境变量，否则手动配置<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">F:\Anaconda3</span><br><span class="line">F:\Anaconda3\Scripts</span><br><span class="line">F:\Anaconda3\Library\bin</span><br></pre></td></tr></table></figure></li></ul><h1 id="二、包管理"><a href="#二、包管理" class="headerlink" title="二、包管理"></a>二、包管理</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置镜像：</span></span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line"><span class="comment"># 显示来源：</span></span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conda list                              列举当前环境下的所有包</span><br><span class="line">conda list -n packagename               列举某个特定名称包</span><br><span class="line">conda install packagename               为当前环境安装某包</span><br><span class="line">conda install -n envname packagename    为某环境安装某包</span><br><span class="line">conda search packagename                搜索某包</span><br><span class="line">conda updata packagename                更新当前环境某包</span><br><span class="line">conda update -n envname packagename     更新某特定环境某包</span><br><span class="line">conda remove packagename                删除当前环境某包</span><br><span class="line">conda remove -n envname packagename     删除某环境环境某包</span><br></pre></td></tr></table></figure><h1 id="三、虚拟环境"><a href="#三、虚拟环境" class="headerlink" title="三、虚拟环境"></a>三、虚拟环境</h1><h2 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h2><ul><li>查看：<code>conda env list</code> 或 <code>conda info -e</code> 或 <code>conda info --envs</code> </li><li>创建：<code>conda create -n env_name python=3.6</code></li><li>同时安装多个包：<code>conda create -n env_name numpy matplotlib python=2.7</code></li><li>再额外安装包：<code>conda install -n env_name [package]</code></li><li>激活(Linux)：<code>source activate env_name</code></li><li>激活(Windows)：<code>activate env_name</code> 或 <code>source activate env_name</code></li><li>关闭(Linux)：<code>source deactivate</code></li><li>关闭(Windows)：<code>deactivate</code> 或 <code>source deactivate</code></li><li>删除包：<code>conda remove -n env_name  [package]</code></li><li>删除环境：<code>conda remove -n env_name --all</code></li><li>导出环境：<code>conda env export &gt; environment.yaml</code></li><li>导入环境(先激活)：<code>conda env update -f=environment.yml</code></li><li>复制克隆：<code>conda create --name &lt;new_env&gt; --clone &lt;old_env&gt;</code></li></ul><h2 id="Jupyter-中使用-conda-虚拟环境"><a href="#Jupyter-中使用-conda-虚拟环境" class="headerlink" title="Jupyter 中使用 conda 虚拟环境"></a>Jupyter 中使用 conda 虚拟环境</h2><ul><li><a href="https://www.cnblogs.com/youyouzaLearn/p/8951809.html" target="_blank" rel="noopener">jupyter中添加conda环境—-kernel配置</a></li><li>1、激活环境：<code>source activate env_name</code></li><li>2、安装 ipykernel：<code>conda install -n env_name ipykernel</code></li><li>3、将环境写入 notebook 的 kernel 中：<br><code>python -m ipykernel install --user --name env_name --display-name env_name</code></li><li>4、删除 kernel：<code>jupyter kernelspec remove env_name</code></li></ul><h1 id="四、Windows-下实际操作"><a href="#四、Windows-下实际操作" class="headerlink" title="四、Windows 下实际操作"></a>四、Windows 下实际操作</h1><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br><span class="line"></span><br><span class="line">conda create -n tf1.13 python=3.6</span><br><span class="line">conda install -n tf1.13 tensorflow=1.13</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> activate tf1.13</span><br><span class="line">conda install -n tf1.13 ipykernel</span><br><span class="line">python -m ipykernel install --user --name tf1.13 --display-name tf1.13</span><br></pre></td></tr></table></figure><h1 id="五、pip-配置镜像"><a href="#五、pip-配置镜像" class="headerlink" title="五、pip 配置镜像"></a>五、pip 配置镜像</h1><ul><li><a href="https://www.cnblogs.com/wqpkita/p/7248525.html" target="_blank" rel="noopener">国内镜像</a></li></ul><h2 id="临时使用："><a href="#临时使用：" class="headerlink" title="临时使用："></a>临时使用：</h2><ul><li>可以在使用pip的时候在后面加上-i参数，指定pip源<br><code>pip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple</code><br><code>pip install numpy -i https://pypi.mirrors.ustc.edu.cn/simple</code></li></ul><h2 id="永久修改："><a href="#永久修改：" class="headerlink" title="永久修改："></a>永久修改：</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@ Linux</span><br><span class="line">mkdir ~/.pip</span><br><span class="line"><span class="built_in">cd</span> ~/.pip</span><br><span class="line">vim pip.conf</span><br><span class="line"></span><br><span class="line">@ Windows</span><br><span class="line">C:\Users\你的用户名\pip\pip.ini</span><br><span class="line">例：C:\Users\Administrator\pip\pip.ini</span><br><span class="line"></span><br><span class="line">文件内容：</span><br><span class="line">[global]</span><br><span class="line">index-url = https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host=pypi.tuna.tsinghua.edu.cn</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;相关链接&quot;&gt;&lt;a href=&quot;#相关链接&quot; class=&quot;headerlink&quot; title=&quot;相关链接&quot;&gt;&lt;/a&gt;相关链接&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;官网：&lt;a href=&quot;https://www.anaconda.com/&quot; targ
      
    
    </summary>
    
      <category term="教程" scheme="http://www.zhuzongkui.top/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="Linux" scheme="http://www.zhuzongkui.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Jupyter Notebook 使用教程</title>
    <link href="http://www.zhuzongkui.top/2019/09/07/jupyter/"/>
    <id>http://www.zhuzongkui.top/2019/09/07/jupyter/</id>
    <published>2019-09-07T03:40:00.000Z</published>
    <updated>2019-09-07T06:16:13.442Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h1><ul><li><a href="https://www.jb51.net/article/140781.htm" target="_blank" rel="noopener">Jupyter notebook远程访问服务器的方法</a></li><li><a href="https://www.cnblogs.com/marsggbo/p/8872528.html" target="_blank" rel="noopener">远程连接服务器jupyter notebook、浏览器以及深度学习可视化方法</a></li><li><a href="https://blog.csdn.net/bitboy_star/article/details/51427306" target="_blank" rel="noopener">远程访问jupyter notebook</a></li><li><a href="https://blog.csdn.net/bingjianIT/article/details/78522533" target="_blank" rel="noopener">jupyter notebook启动出错解决方法</a></li><li><font color="#FF0000">【推荐】</font><a href="https://zhuanlan.zhihu.com/p/32320214" target="_blank" rel="noopener">最详尽使用指南：超快上手Jupyter Notebook</a></li><li>修改主题： <a href="https://github.com/dunovank/jupyter-themes" target="_blank" rel="noopener">https://github.com/dunovank/jupyter-themes</a></li><li>安装插件：<a href="https://github.com/ipython-contrib/jupyter_contrib_nbextensions" target="_blank" rel="noopener">https://github.com/ipython-contrib/jupyter_contrib_nbextensions</a></li></ul><h1 id="一、Jupyter-Notebook"><a href="#一、Jupyter-Notebook" class="headerlink" title="一、Jupyter Notebook"></a>一、Jupyter Notebook</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install jupyter           # 先检查，后安装</span><br><span class="line">jupyter notebook --generate-config      # 记录生成的文件</span><br></pre></td></tr></table></figure><h2 id="密码"><a href="#密码" class="headerlink" title="密码"></a>密码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">python  <span class="comment"># 命令行</span></span><br><span class="line"><span class="keyword">from</span> notebook.auth <span class="keyword">import</span> passwd</span><br><span class="line">passwd()</span><br><span class="line"></span><br><span class="line">Enter password:                         <span class="comment"># 输入密码</span></span><br><span class="line">Verify password:                        <span class="comment"># 验证密码</span></span><br><span class="line">Out[<span class="number">2</span>]: <span class="string">'sha1:ce23dxxxxxxxxxx'</span>          <span class="comment"># 复制密文</span></span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><ul><li>打开上面生成的文件</li><li>vim ~/.jupyter/jupyter_notebook_config.py<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 在文件最后面添加：</span><br><span class="line">c.NotebookApp.ip=&apos;*&apos;                    # 也可以指定具体 ip</span><br><span class="line">c.NotebookApp.password = u&apos;sha:ce...刚才复制的那个密文&apos;</span><br><span class="line">c.NotebookApp.open_browser = False      # 禁止自动打开浏览器</span><br><span class="line">c.NotebookApp.port = 8888               # 随便指定一个端口</span><br><span class="line">c.InteractiveShellApp.matplotlib = &apos;inline&apos;  # 显示Matplotlib的图形</span><br></pre></td></tr></table></figure></li></ul><h2 id="打开"><a href="#打开" class="headerlink" title="打开"></a>打开</h2><ul><li>在指定目录打开cmd或者命令行，输入：<code>jupyter notebook</code></li><li>浏览器输入地址：<code>localhost:8888</code></li></ul><h1 id="二、插件"><a href="#二、插件" class="headerlink" title="二、插件"></a>二、插件</h1><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python -m pip install jupyter_contrib_nbextensions</span><br><span class="line">jupyter contrib nbextension install --user</span><br><span class="line">jupyter nbextension enable codefolding/main</span><br></pre></td></tr></table></figure><h2 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h2><ul><li>重新打开jupyter，刷新首页，点击：<code>Nbextensions</code>，选择插件</li><li>非正常情况下：http:ip地址:8888/nbextensions?nbextension=codefolding/main</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Codefolding             # 折叠标题</span><br><span class="line">Collapsible headings    # 折叠代码</span><br><span class="line">ExecuteTime             # 执行时间</span><br><span class="line">Notify                  # 发送通知</span><br><span class="line">Table of Contents       # 自动生成目录</span><br></pre></td></tr></table></figure><h1 id="三、输入命令"><a href="#三、输入命令" class="headerlink" title="三、输入命令"></a>三、输入命令</h1><ul><li>在命令前加一个英文感叹号：<code>!</code></li><li>例如：<code>! cd data_dir/</code></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;相关链接&quot;&gt;&lt;a href=&quot;#相关链接&quot; class=&quot;headerlink&quot; title=&quot;相关链接&quot;&gt;&lt;/a&gt;相关链接&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.jb51.net/article/14078
      
    
    </summary>
    
      <category term="教程" scheme="http://www.zhuzongkui.top/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="Linux" scheme="http://www.zhuzongkui.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>scikit-learn 之 文本分类（特征提取、选择、评估）</title>
    <link href="http://www.zhuzongkui.top/2019/08/31/sklearn/"/>
    <id>http://www.zhuzongkui.top/2019/08/31/sklearn/</id>
    <published>2019-08-31T07:06:34.000Z</published>
    <updated>2019-09-02T07:23:02.540Z</updated>
    
    <content type="html"><![CDATA[<h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><ul><li>英文官网：<a href="https://scikit-learn.org/stable/" target="_blank" rel="noopener">https://scikit-learn.org/stable/</a></li><li>中文官网：<a href="https://sklearn.apachecn.org/" target="_blank" rel="noopener">https://sklearn.apachecn.org/</a></li><li><a href="http://sklearn.lzjqsdd.com/" target="_blank" rel="noopener">官网翻译1</a>、<a href="http://www.studyai.cn/" target="_blank" rel="noopener">官网翻译2</a></li><li><a href="https://www.cnblogs.com/lianyingteng/p/7811126.html" target="_blank" rel="noopener">ML神器：sklearn的快速使用</a></li><li><a href="https://blog.csdn.net/kevinelstri/article/details/55520591" target="_blank" rel="noopener">【scikit-learn】01~07</a></li><li><a href="https://blog.csdn.net/sinat_26917383/article/details/75199996?locationNum=3&amp;fps=1" target="_blank" rel="noopener">python + sklearn ︱分类效果评估——acc、recall、F1、ROC、回归、距离</a></li><li><a href="https://www.cnblogs.com/CheeseZH/p/8644893.html" target="_blank" rel="noopener">【ZH奶酪】如何用sklearn计算中文文本TF-IDF？</a></li><li><a href="https://blog.csdn.net/steven_ffd/article/details/84881063" target="_blank" rel="noopener">sklearn中CountVectorizer里token_pattern默认参数解读</a></li><li><a href="https://my.oschina.net/u/2293326/blog/1838918" target="_blank" rel="noopener">tfidf_CountVectorizer 与 TfidfTransformer 保存和测试</a></li><li><a href="https://blog.csdn.net/levy_cui/article/details/75011406?utm_source=blogxgwz1" target="_blank" rel="noopener">sklearn训练后使用pickle、joblib保存与恢复模型</a></li></ul><h2 id="分类器、指标、特征提取、特征选择"><a href="#分类器、指标、特征提取、特征选择" class="headerlink" title="分类器、指标、特征提取、特征选择"></a>分类器、指标、特征提取、特征选择</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> GaussianNB</span><br><span class="line"><span class="keyword">from</span> sklearn.naive_bayes <span class="keyword">import</span> MultinomialNB</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> ExtraTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> BernoulliRBM</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> RadiusNeighborsClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> libsvm</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> AdaBoostClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> BaggingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> ExtraTreesClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> VotingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> QuadraticDiscriminantAnalysis <span class="keyword">as</span> QDA</span><br><span class="line"><span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis <span class="keyword">as</span> LDA</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectPercentile</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br></pre></td></tr></table></figure><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_file</span><span class="params">(filename)</span>:</span></span><br><span class="line">    all_data, all_tag = [], []</span><br><span class="line">    <span class="keyword">with</span> open(filename, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fr:</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fr:</span><br><span class="line">            row = json.loads(line)</span><br><span class="line">            all_data.append(row[<span class="string">"question"</span>])</span><br><span class="line">            all_tag.append(row[<span class="string">"Coarse"</span>])</span><br><span class="line">    <span class="keyword">return</span> all_data, all_tag</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_train_test</span><span class="params">()</span>:</span></span><br><span class="line">    train_file = <span class="string">'./QC/data/问题集/trainquestion.json'</span></span><br><span class="line">    test_file = <span class="string">'./QC/data/问题集/testquestion.json'</span></span><br><span class="line">    x_train, y_train = read_file(train_file)</span><br><span class="line">    x_test, y_test = read_file(test_file)</span><br><span class="line">    <span class="keyword">return</span> x_train, y_train, x_test, y_test</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_ngram_seg</span><span class="params">(sen, n)</span>:</span></span><br><span class="line">    ngram_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(sen)):</span><br><span class="line">        <span class="keyword">if</span> i + n &lt;= len(sen):</span><br><span class="line">            ngram_list.append(sen[i: i+n])</span><br><span class="line">    <span class="keyword">return</span> ngram_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_seg</span><span class="params">(DATA)</span>:</span></span><br><span class="line">    <span class="comment"># return [" ".join(jieba.lcut(d)) for d in DATA]</span></span><br><span class="line">    <span class="keyword">return</span> [<span class="string">" "</span>.join(get_ngram_seg(d, <span class="number">1</span>)) <span class="keyword">for</span> d <span class="keyword">in</span> DATA]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PRF</span><span class="params">(y_true, y_pred)</span>:</span></span><br><span class="line">    acc_test = metrics.accuracy_score(y_true, y_pred)</span><br><span class="line">    P_test = metrics.precision_score(y_true, y_pred, average=<span class="string">'macro'</span>)</span><br><span class="line">    R_test = metrics.recall_score(y_true, y_pred, average=<span class="string">'macro'</span>)</span><br><span class="line">    F_test = metrics.f1_score(y_true, y_pred, average=<span class="string">'macro'</span>)</span><br><span class="line">    print(acc_test, P_test, R_test, F_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CLF</span><span class="params">(model)</span>:</span></span><br><span class="line">    x_train, y_train, x_test, y_test = get_train_test()</span><br><span class="line">    x_train_seg = get_seg(x_train)</span><br><span class="line">    x_test_seg = get_seg(x_test)</span><br><span class="line"></span><br><span class="line">    vectorizer = CountVectorizer(token_pattern=<span class="string">'\\b\\w+\\b'</span>)</span><br><span class="line">    vectorizer.fit(x_train_seg)</span><br><span class="line">    <span class="comment"># print(vectorizer.vocabulary_)  # 词汇</span></span><br><span class="line"></span><br><span class="line">    bow_train = vectorizer.transform(x_train_seg)  <span class="comment"># 词袋特征   one-hot向量</span></span><br><span class="line">    bow_test = vectorizer.transform(x_test_seg)</span><br><span class="line"><span class="comment">#     print("特征提取前：", end=' ')</span></span><br><span class="line"><span class="comment">#     print(bow_train.shape, end=' ')</span></span><br><span class="line"><span class="comment">#     print(bow_test.shape, end='\t')</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     tfidf_transformer = TfidfTransformer()</span></span><br><span class="line"><span class="comment">#     tfidf_transformer.fit(bow_train.toarray())</span></span><br><span class="line"><span class="comment">#     tfidf_train = tfidf_transformer.transform(bow_train)  # TFIDF特征</span></span><br><span class="line"><span class="comment">#     tfidf_test = tfidf_transformer.transform(bow_test)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># FS = SelectKBest(chi2, k=3000)  # 选择topK特征</span></span><br><span class="line">    FS = SelectPercentile(chi2, percentile=<span class="number">100</span>)  <span class="comment"># 选择百分比</span></span><br><span class="line">    bow_train_new = FS.fit_transform(bow_train, np.array(y_train))</span><br><span class="line">    feature_index = FS.get_support(<span class="keyword">True</span>)  <span class="comment"># 特征选择后，保留的特征维度</span></span><br><span class="line">    bow_test_new = bow_test[:, feature_index]</span><br><span class="line"></span><br><span class="line"><span class="comment">#     print("特征提取后：", end=' ')</span></span><br><span class="line"><span class="comment">#     print(bow_train_new.shape, end=' ')</span></span><br><span class="line"><span class="comment">#     print(bow_test_new.shape, end='\t')</span></span><br><span class="line"></span><br><span class="line">    clf = model.fit(bow_train_new.toarray(), np.array(y_train))</span><br><span class="line">    y_pred = clf.predict(bow_test_new.toarray())</span><br><span class="line">    print(model.__class__.__name__, end=<span class="string">'\t'</span>)</span><br><span class="line">    PRF(y_test, y_pred)</span><br><span class="line">    <span class="comment"># print(metrics.classification_report(y_test, y_pred))</span></span><br></pre></td></tr></table></figure><h2 id="测试不同分类器"><a href="#测试不同分类器" class="headerlink" title="测试不同分类器"></a>测试不同分类器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CLF(GaussianNB())</span></span><br><span class="line">CLF(MultinomialNB())</span><br><span class="line">CLF(LogisticRegression())</span><br><span class="line">CLF(SGDClassifier())</span><br><span class="line">CLF(DecisionTreeClassifier())</span><br><span class="line">CLF(ExtraTreeClassifier())</span><br><span class="line">CLF(MLPClassifier())</span><br><span class="line"><span class="comment"># CLF(BernoulliRBM())</span></span><br><span class="line">CLF(KNeighborsClassifier())</span><br><span class="line"><span class="comment"># CLF(RadiusNeighborsClassifier())</span></span><br><span class="line">CLF(SVC(C=<span class="number">1</span>, kenerl=<span class="string">'linear'</span>, gamma=<span class="number">1</span>, shrinkling=<span class="keyword">True</span>, probability))  <span class="comment"># 基于libsvm实现</span></span><br><span class="line">CLF(LinearSVC())</span><br><span class="line"><span class="comment"># CLF(libsvm)</span></span><br><span class="line">CLF(AdaBoostClassifier())</span><br><span class="line">CLF(BaggingClassifier())</span><br><span class="line">CLF(ExtraTreesClassifier())</span><br><span class="line">CLF(GradientBoostingClassifier())</span><br><span class="line">CLF(RandomForestClassifier())</span><br><span class="line"><span class="comment"># CLF(VotingClassifier())</span></span><br><span class="line">CLF(QDA())</span><br><span class="line">CLF(LDA())</span><br><span class="line">CLF(XGBClassifier())</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;相关链接&quot;&gt;&lt;a href=&quot;#相关链接&quot; class=&quot;headerlink&quot; title=&quot;相关链接&quot;&gt;&lt;/a&gt;相关链接&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;英文官网：&lt;a href=&quot;https://scikit-learn.org/stable/&quot; target=&quot;
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="统计学习" scheme="http://www.zhuzongkui.top/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>深度学习框架 - 学习链接</title>
    <link href="http://www.zhuzongkui.top/2019/08/12/deeplearning_framework/"/>
    <id>http://www.zhuzongkui.top/2019/08/12/deeplearning_framework/</id>
    <published>2019-08-12T00:40:30.000Z</published>
    <updated>2019-09-07T06:04:05.229Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、指定-GPU-的-id"><a href="#一、指定-GPU-的-id" class="headerlink" title="一、指定 GPU 的 id"></a>一、指定 GPU 的 id</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">1</span> python my_script.py</span><br><span class="line"></span><br><span class="line">export CUDA_VISIBLE_DEVICES=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="string">"0"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">torch.cuda.set_device(id)</span><br></pre></td></tr></table></figure><h1 id="二、深度学习框架"><a href="#二、深度学习框架" class="headerlink" title="二、深度学习框架"></a>二、深度学习框架</h1><ul><li>Neural Networks and Deep Learning：<a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/</a></li></ul><h2 id="一、TensorFlow"><a href="#一、TensorFlow" class="headerlink" title="一、TensorFlow"></a>一、TensorFlow</h2><ul><li><a href="https://www.tensorflow.org/api_docs/python/" target="_blank" rel="noopener">官方API www.tensorflow.org</a></li><li><a href="https://tensorflow.google.cn/api_docs/python" target="_blank" rel="noopener">国内API tensorflow.google.cn</a></li><li><a href="https://zhuanlan.zhihu.com/p/29104758" target="_blank" rel="noopener">TensorFlow从0到1丨开篇：Hello TensorFlow ！</a></li><li>教学：<a href="http://www.tensorflownews.com/" target="_blank" rel="noopener">http://www.tensorflownews.com/</a></li><li><a href="https://www.bilibili.com/video/av16001891" target="_blank" rel="noopener">Tensorflow 搭建自己的神经网络 (莫烦 Python 教程)</a></li><li><a href="https://morvanzhou.github.io" target="_blank" rel="noopener">莫烦 https://github.com/MorvanZhou 主页</a></li><li><a href="https://www.cnblogs.com/hellocwh/p/5527141.html" target="_blank" rel="noopener">TensorFlow 深度学习笔记 TensorFlow实现与优化深度神经网络</a></li></ul><h2 id="二、Keras"><a href="#二、Keras" class="headerlink" title="二、Keras"></a>二、Keras</h2><ul><li>英文文档 <a href="https://keras.io/" target="_blank" rel="noopener">https://keras.io/</a></li><li>中文文档 <a href="https://keras.io/zh/" target="_blank" rel="noopener">https://keras.io/zh/</a></li><li>别人翻译 <a href="http://keras-cn.readthedocs.io/en/latest/" target="_blank" rel="noopener">http://keras-cn.readthedocs.io/en/latest/</a></li><li>莫烦 keras 教程 <a href="https://morvanzhou.github.io/tutorials/machine-learning/keras/" target="_blank" rel="noopener">https://morvanzhou.github.io/tutorials/machine-learning/keras/</a></li><li><a href="http://www.cnblogs.com/lc1217/p/7132364.html" target="_blank" rel="noopener">深度学习：Keras入门(一)之基础篇</a></li><li><a href="https://www.jianshu.com/p/795a5e2cd10c" target="_blank" rel="noopener">《Keras 实现 LSTM》笔记</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">keras离线官方文档 https://blog.csdn.net/nima1994/article/details/80579240</span><br><span class="line"></span><br><span class="line">keras中文文档： </span><br><span class="line">https://keras.io/zh/（官方） </span><br><span class="line">http://keras-cn.readthedocs.io/en/latest/</span><br><span class="line"></span><br><span class="line">由于官方文档（更新似乎快点儿）经常访问不了，所以下载查看。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">1. 下载包 或者 如下命令使用git克隆。</span><br><span class="line">git clone https://github.com/keras-team/keras-docs-zh</span><br><span class="line"></span><br><span class="line">2. 安装mkdocs（pip install mkdocs）后，进入keras-docs-zh文件夹，依次使用如下命令：</span><br><span class="line">mkdocs build#生成静态文件</span><br><span class="line">mkdocs serve#启动本地服务</span><br><span class="line"></span><br><span class="line">3. 在浏览器输入进行本地访问：</span><br><span class="line">http://localhost:8000</span><br><span class="line"></span><br><span class="line">使用mkdocs构建的静态网站，可类似食用，并可使用git同步更新</span><br><span class="line"></span><br><span class="line">http://127.0.0.1:8000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## MkDocs 快速入门 https://blog.csdn.net/wirelessqa/article/details/78173401?locationNum=5&amp;fps=1</span><br></pre></td></tr></table></figure><h2 id="三、PyTorch"><a href="#三、PyTorch" class="headerlink" title="三、PyTorch"></a>三、PyTorch</h2><ul><li>官网：<a href="https://pytorch.org/" target="_blank" rel="noopener">https://pytorch.org/</a></li><li>英文文档：<a href="https://pytorch.org/docs/stable/index.html" target="_blank" rel="noopener">https://pytorch.org/docs/stable/index.html</a></li><li>中文文档：<a href="https://pytorch-cn.readthedocs.io/zh/latest/" target="_blank" rel="noopener">https://pytorch-cn.readthedocs.io/zh/latest/</a></li><li>PyTorch 中文手册：<a href="https://github.com/zergtant/pytorch-handbook" target="_blank" rel="noopener">https://github.com/zergtant/pytorch-handbook</a></li><li>神经网络框架-Pytorch使用介绍：<a href="https://blog.csdn.net/zzulp/article/details/80573331" target="_blank" rel="noopener">https://blog.csdn.net/zzulp/article/details/80573331</a></li></ul><h2 id="四、FastAI"><a href="#四、FastAI" class="headerlink" title="四、FastAI"></a>四、FastAI</h2><ul><li>论文网址：<a href="http://nlp.fast.ai/category/classification.html" target="_blank" rel="noopener">http://nlp.fast.ai/category/classification.html</a></li><li>Fast.AI 第一课学习笔记 : <a href="https://www.jianshu.com/p/df6446057004" target="_blank" rel="noopener">https://www.jianshu.com/p/df6446057004</a></li><li>Fast.AI课程文件、教学视频及学习环境虚拟机下载分享：<a href="https://www.jianshu.com/p/2fe22a6b0ecb" target="_blank" rel="noopener">https://www.jianshu.com/p/2fe22a6b0ecb</a></li><li>【深度学习】从fast.ai学到的十大技巧：<a href="https://blog.csdn.net/ChenVast/article/details/81480865" target="_blank" rel="noopener">https://blog.csdn.net/ChenVast/article/details/81480865</a></li><li>使用fastai训练的一个性别识别模型：<a href="https://www.cnblogs.com/ctsch/p/9498327.html" target="_blank" rel="noopener">https://www.cnblogs.com/ctsch/p/9498327.html</a></li><li><a href="https://github.com/fastai/fastai/tree/master/courses/dl2/imdb_scripts" target="_blank" rel="noopener">https://github.com/fastai/fastai/tree/master/courses/dl2/imdb_scripts</a></li></ul><h2 id="五、MXNet"><a href="#五、MXNet" class="headerlink" title="五、MXNet"></a>五、MXNet</h2><ul><li><a href="https://github.com/apache/incubator-mxnet" target="_blank" rel="noopener">https://github.com/apache/incubator-mxnet</a></li><li>《动手学深度学习》：<a href="http://zh.gluon.ai/" target="_blank" rel="noopener">http://zh.gluon.ai/</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;一、指定-GPU-的-id&quot;&gt;&lt;a href=&quot;#一、指定-GPU-的-id&quot; class=&quot;headerlink&quot; title=&quot;一、指定 GPU 的 id&quot;&gt;&lt;/a&gt;一、指定 GPU 的 id&lt;/h1&gt;&lt;figure class=&quot;highlight pyth
      
    
    </summary>
    
      <category term="总结" scheme="http://www.zhuzongkui.top/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="NLP" scheme="http://www.zhuzongkui.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Vim 基本配置</title>
    <link href="http://www.zhuzongkui.top/2019/08/11/vim/"/>
    <id>http://www.zhuzongkui.top/2019/08/11/vim/</id>
    <published>2019-08-11T04:13:31.000Z</published>
    <updated>2019-08-22T03:35:05.703Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Vim-基本配置"><a href="#Vim-基本配置" class="headerlink" title="Vim 基本配置"></a>Vim 基本配置</h1><h2 id="一、教程"><a href="#一、教程" class="headerlink" title="一、教程"></a>一、教程</h2><ul><li><a href="http://harttle.land/2013/11/08/vim-config.html" target="_blank" rel="noopener">Vim初级：配置和使用</a></li><li><a href="https://www.cnblogs.com/cjy15639731813/p/5886158.html" target="_blank" rel="noopener">Vim配置（python版）</a></li></ul><h2 id="二、李老师的-vim-配置-主页"><a href="#二、李老师的-vim-配置-主页" class="headerlink" title="二、李老师的 vim 配置 主页"></a>二、李老师的 vim 配置 <a href="http://hlt.suda.edu.cn/~zhli/" target="_blank" rel="noopener">主页</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">set nocompatible &quot; 关闭 vi 兼容模式</span><br><span class="line">syntax on &quot; 自动语法高亮</span><br><span class="line">set number &quot; 显示行号</span><br><span class="line">set cursorline &quot; 突出显示当前行</span><br><span class="line">set ruler &quot; 打开状态栏标尺</span><br><span class="line">set shiftwidth=4 &quot; 设定 &lt;&lt; 和 &gt;&gt; 命令移动时的宽度为 4</span><br><span class="line">set softtabstop=4 &quot; 使得按退格键时可以一次删掉 4 个空格</span><br><span class="line">set tabstop=4 &quot; 设定 tab 长度为 4</span><br><span class="line">set nobackup &quot; 覆盖文件时不备份</span><br><span class="line">set autochdir &quot; 自动切换当前目录为当前文件所在的目录</span><br><span class="line">filetype plugin indent on &quot; 开启插件</span><br><span class="line">set backupcopy=yes &quot; 设置备份时的行为为覆盖</span><br><span class="line">set ignorecase smartcase &quot; 搜索时忽略大小写，但在有一个或以上大写字母时仍保持对大小写敏感</span><br><span class="line">set nowrapscan &quot; 禁止在搜索到文件两端时重新搜索</span><br><span class="line">set incsearch &quot; 输入搜索内容时就显示搜索结果</span><br><span class="line">set hlsearch &quot; 搜索时高亮显示被找到的文本</span><br><span class="line">set noerrorbells &quot; 关闭错误信息响铃</span><br><span class="line">set novisualbell &quot; 关闭使用可视响铃代替呼叫</span><br><span class="line">set t_vb= &quot; 置空错误铃声的终端代码</span><br><span class="line">&quot; set showmatch &quot; 插入括号时，短暂地跳转到匹配的对应括号</span><br><span class="line">&quot; set matchtime=2 &quot; 短暂跳转到匹配括号的时间</span><br><span class="line">set magic &quot; 设置魔术</span><br><span class="line">set hidden &quot; 允许在有未保存的修改时切换缓冲区，此时的修改由 vim 负责保存</span><br><span class="line">set guioptions-=T &quot; 隐藏工具栏</span><br><span class="line">set guioptions-=m &quot; 隐藏菜单栏</span><br><span class="line">set smartindent &quot; 开启新行时使用智能自动缩进</span><br><span class="line">set backspace=indent,eol,start</span><br><span class="line">&quot; 不设定在插入状态无法用退格键和 Delete 键删除回车符</span><br><span class="line">set cmdheight=1 &quot; 设定命令行的行数为 1</span><br><span class="line">set laststatus=2 &quot; 显示状态栏 (默认值为 1, 无法显示状态栏)</span><br><span class="line">set statusline=\ %&lt;%F[%1*%M%*%n%R%H]%=\ %y\ %0(%&#123;&amp;fileformat&#125;\ %&#123;&amp;encoding&#125;\ %c:%l/%L%)\ </span><br><span class="line">&quot; 设置在状态行显示的信息</span><br><span class="line">&quot;set foldenable &quot; 开始折叠</span><br><span class="line">&quot;set foldmethod=syntax &quot; 设置语法折叠</span><br><span class="line">set foldcolumn=0 &quot; 设置折叠区域的宽度</span><br><span class="line">setlocal foldlevel=1 &quot; 设置折叠层数为</span><br><span class="line">&quot; set foldclose=all &quot; 设置为自动关闭折叠 </span><br><span class="line"> nnoremap &lt;space&gt; @=((foldclosed(line(&apos;.&apos;)) &lt; 0) ? &apos;zc&apos; : &apos;zo&apos;)&lt;CR&gt;</span><br><span class="line">&quot; 用空格键来开关折叠</span><br></pre></td></tr></table></figure><h2 id="三、python-注释"><a href="#三、python-注释" class="headerlink" title="三、python 注释"></a>三、python 注释</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">多行注释：</span><br><span class="line">  1. 首先按esc进入命令行模式下，按下Ctrl + v，进入列（也叫区块）模式;</span><br><span class="line">  2. 在行首使用上下键选择需要注释的多行;</span><br><span class="line">  3. 按下键盘（大写）“I”键，进入插入模式；</span><br><span class="line">  4. 然后输入注释符（“//”、“#”等）;</span><br><span class="line">  5. 最后按下“Esc”键。</span><br><span class="line">注：在按下esc键后，会稍等一会才会出现注释，不要着急~~时间很短的</span><br><span class="line"></span><br><span class="line">删除多行注释：</span><br><span class="line">  1. 首先按esc进入命令行模式下，按下Ctrl + v, 进入列模式;</span><br><span class="line">  2. 选定要取消注释的多行;</span><br><span class="line">  3. 按下“x”或者“d”.</span><br><span class="line">注意：如果是“//”注释，那需要执行两次该操作，如果是“#”注释，一次即可</span><br></pre></td></tr></table></figure><h2 id="四、剪切-复制-粘贴"><a href="#四、剪切-复制-粘贴" class="headerlink" title="四、剪切/复制/粘贴"></a>四、剪切/复制/粘贴</h2><ul><li><a href="https://blog.csdn.net/lanxinju/article/details/5727262" target="_blank" rel="noopener">vi/vim复制粘贴命令</a></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 一行</span><br><span class="line">yy          复制一行</span><br><span class="line">dd          剪切一行</span><br><span class="line">p（小写）    粘贴（光标往后）</span><br><span class="line">P（大写）    粘贴（光标往前）</span><br><span class="line"></span><br><span class="line"># 多行</span><br><span class="line">先将光标移到多行的开始处</span><br><span class="line">esc v 进入可视模式</span><br><span class="line">再将光标移到多行的结尾处</span><br><span class="line">y           复制上面选中的</span><br><span class="line">d           剪切选定块到缓冲区</span><br><span class="line">p（小写）    粘贴（光标往后）</span><br><span class="line">P（大写）    粘贴（光标往前）</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Vim-基本配置&quot;&gt;&lt;a href=&quot;#Vim-基本配置&quot; class=&quot;headerlink&quot; title=&quot;Vim 基本配置&quot;&gt;&lt;/a&gt;Vim 基本配置&lt;/h1&gt;&lt;h2 id=&quot;一、教程&quot;&gt;&lt;a href=&quot;#一、教程&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="教程" scheme="http://www.zhuzongkui.top/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="Linux" scheme="http://www.zhuzongkui.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>NLP 基本任务</title>
    <link href="http://www.zhuzongkui.top/2019/08/11/nlp_base_task/"/>
    <id>http://www.zhuzongkui.top/2019/08/11/nlp_base_task/</id>
    <published>2019-08-11T04:10:13.420Z</published>
    <updated>2019-08-11T04:11:23.454Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="NLP基本任务"><a href="#NLP基本任务" class="headerlink" title="NLP基本任务"></a><a href="https://blog.csdn.net/lz_peter/article/details/81588430" target="_blank" rel="noopener">NLP基本任务</a></h1><h2 id="1、词法分析（Lexical-Analysis）：对自然语言进行词汇层面的分析，是NLP基础性工作"><a href="#1、词法分析（Lexical-Analysis）：对自然语言进行词汇层面的分析，是NLP基础性工作" class="headerlink" title="1、词法分析（Lexical Analysis）：对自然语言进行词汇层面的分析，是NLP基础性工作"></a>1、词法分析（Lexical Analysis）：对自然语言进行词汇层面的分析，是NLP基础性工作</h2><ul><li>分词（Word Segmentation/Tokenization）：对没有明显边界的文本进行切分，得到词序列</li><li>新词发现（New Words Identification）：找出文本中具有新形势、新意义或是新用法的词</li><li>形态分析（Morphological Analysis）：分析单词的形态组成，包括词干（Sterms）、词根（Roots）、词缀（Prefixes and Suffixes）等</li><li>词性标注（Part-of-speech Tagging）：确定文本中每个词的词性。词性包括动词（Verb）、名词（Noun）、代词（pronoun）等</li><li>拼写校正（Spelling Correction）：找出拼写错误的词并进行纠正</li></ul><h2 id="2、句子分析（Sentence-Analysis）：对自然语言进行句子层面的分析，包括句法分析和其他句子级别的分析任务"><a href="#2、句子分析（Sentence-Analysis）：对自然语言进行句子层面的分析，包括句法分析和其他句子级别的分析任务" class="headerlink" title="2、句子分析（Sentence Analysis）：对自然语言进行句子层面的分析，包括句法分析和其他句子级别的分析任务"></a>2、句子分析（Sentence Analysis）：对自然语言进行句子层面的分析，包括句法分析和其他句子级别的分析任务</h2><ul><li>组块分析（Chunking）：标出句子中的短语块，例如名词短语（NP），动词短语（VP）等</li><li>超级标签标注（Super Tagging）：给每个句子中的每个词标注上超级标签，超级标签是句法树中与该词相关的树形结构</li><li>成分句法分析（Constituency Parsing）：分析句子的成分，给出一棵树由终结符和非终结符构成的句法树</li><li>依存句法分析（Dependency Parsing）：分析句子中词与词之间的依存关系，给一棵由词语依存关系构成的依存句法树</li><li>语言模型（Language Modeling）：对给定的一个句子进行打分，该分数代表句子合理性（流畅度）的程度</li><li>语种识别（Language Identification）：给定一段文本，确定该文本属于哪个语种<br>句子边界检测（Sentence Boundary Detection）：给没有明显句子边界的文本加边界</li></ul><h2 id="3、语义分析（Semantic-Analysis）：对给定文本进行分析和理解，形成能勾够表达语义的形式化表示或分布式表示"><a href="#3、语义分析（Semantic-Analysis）：对给定文本进行分析和理解，形成能勾够表达语义的形式化表示或分布式表示" class="headerlink" title="3、语义分析（Semantic Analysis）：对给定文本进行分析和理解，形成能勾够表达语义的形式化表示或分布式表示"></a>3、语义分析（Semantic Analysis）：对给定文本进行分析和理解，形成能勾够表达语义的形式化表示或分布式表示</h2><ul><li>词义消歧（Word Sense Disambiguation）：对有歧义的词，确定其准确的词义</li><li>语义角色标注（Semantic Role Labeling）：标注句子中的语义角色类标，语义角色，语义角色包括施事、受事、影响等</li><li>抽象语义表示分析（Abstract Meaning Representation Parsing）：AMR是一种抽象语义表示形式，AMR parser把句子解析成AMR结构</li><li>一阶谓词逻辑演算（First Order Predicate Calculus）：使用一阶谓词逻辑系统表达语义</li><li>框架语义分析（Frame Semantic Parsing）：根据框架语义学的观点，对句子进行语义分析</li><li>词汇/句子/段落的向量化表示（Word/Sentence/Paragraph Vector）：研究词汇、句子、段落的向量化方法，向量的性质和应用</li></ul><h2 id="4、信息抽取（Information-Extraction）：从无结构文本中抽取结构化的信息"><a href="#4、信息抽取（Information-Extraction）：从无结构文本中抽取结构化的信息" class="headerlink" title="4、信息抽取（Information Extraction）：从无结构文本中抽取结构化的信息"></a>4、信息抽取（Information Extraction）：从无结构文本中抽取结构化的信息</h2><ul><li>命名实体识别（Named Entity Recognition）：从文本中识别出命名实体，实体一般包括人名、地名、机构名、时间、日期、货币、百分比等</li><li>实体消歧（Entity Disambiguation）：确定实体指代的现实世界中的对象</li><li>术语抽取（Terminology/Giossary Extraction）：从文本中确定术语</li><li>共指消解（Coreference Resolution）：确定不同实体的等价描述，包括代词消解和名词消解</li><li>关系抽取（Relationship Extraction）：确定文本中两个实体之间的关系类型</li><li>事件抽取（Event Extraction）：从无结构的文本中抽取结构化事件</li><li>情感分析（Sentiment Analysis）：对文本的主观性情绪进行提取</li><li>意图识别（Intent Detection）：对话系统中的一个重要模块，对用户给定的对话内容进行分析，识别用户意图</li><li>槽位填充（Slot Filling）：对话系统中的一个重要模块，从对话内容中分析出于用户意图相关的有效信息</li></ul><h2 id="5、顶层任务（High-level-Tasks）：直接面向普通用户，提供自然语言处理产品服务的系统级任务，会用到多个层面的自然语言处理技术"><a href="#5、顶层任务（High-level-Tasks）：直接面向普通用户，提供自然语言处理产品服务的系统级任务，会用到多个层面的自然语言处理技术" class="headerlink" title="5、顶层任务（High-level Tasks）：直接面向普通用户，提供自然语言处理产品服务的系统级任务，会用到多个层面的自然语言处理技术"></a>5、顶层任务（High-level Tasks）：直接面向普通用户，提供自然语言处理产品服务的系统级任务，会用到多个层面的自然语言处理技术</h2><ul><li>机器翻译（Machine Translation）：通过计算机自动化的把一种语言翻译成另外一种语言</li><li>文本摘要（Text summarization/Simplication）：对较长文本进行内容梗概的提取</li><li>问答系统（Question-Answering Systerm）：针对用户提出的问题，系统给出相应的答案</li><li>对话系统（Dialogue Systerm）：能够与用户进行聊天对话，从对话中捕获用户的意图，并分析执行</li><li>阅读理解（Reading Comprehension）：机器阅读完一篇文章后，给定一些文章相关问题，机器能够回答</li><li>自动文章分级（Automatic Essay Grading）：给定一篇文章，对文章的质量进行打分或分级</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;NLP基本任务&quot;&gt;&lt;a href=&quot;#NLP基本任务&quot; class=&quot;headerlink&quot; title=&quot;NLP基本任务&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://blog.csdn.net/lz_peter/article/deta
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NLP" scheme="http://www.zhuzongkui.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>解压缩命令-使用教程</title>
    <link href="http://www.zhuzongkui.top/2019/08/11/compress_commit/"/>
    <id>http://www.zhuzongkui.top/2019/08/11/compress_commit/</id>
    <published>2019-08-11T03:09:41.000Z</published>
    <updated>2019-08-11T04:04:54.160Z</updated>
    
    <content type="html"><![CDATA[<h1 id="解压缩命令"><a href="#解压缩命令" class="headerlink" title="解压缩命令"></a>解压缩命令</h1><ul><li>后缀：<code>.zip</code>, <code>.tar</code>, <code>.gz</code>, <code>.bz2</code>, <code>.tar.gz</code>, <code>.tar.bz2</code>, <code>.rar</code></li><li><a href="https://www.cnblogs.com/yhjoker/p/7568680.html" target="_blank" rel="noopener">Linux下文件的打包、解压缩指令——tar，gzip，bzip2，unzip，rar</a></li></ul><h2 id="zip-unzip"><a href="#zip-unzip" class="headerlink" title="zip / unzip"></a><a href="https://man.linuxde.net/zip" target="_blank" rel="noopener">zip</a> / <a href="https://man.linuxde.net/unzip" target="_blank" rel="noopener">unzip</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">解压：unzip filename.zip  # 默认解压到当前目录，-d ./</span><br><span class="line">压缩：zip -r filename.zip dirname</span><br></pre></td></tr></table></figure><h2 id="tar"><a href="#tar" class="headerlink" title="tar"></a><a href="https://man.linuxde.net/tar" target="_blank" rel="noopener">tar</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-j：使用bzip2进行解压缩，一般使用.tar.bz2后缀</span><br><span class="line">-z：使用gzip进行解压缩，一般使用.tar.gz后缀</span><br><span class="line">-c：压缩，建立新的备份文件</span><br><span class="line">-x：解压，从备份文件中还原文件</span><br><span class="line">-v：显示指令执行过程</span><br><span class="line">-f：指定备份文件</span><br><span class="line"></span><br><span class="line">解包：tar zxvf filename.tar</span><br><span class="line">打包：tar zcvf filename.tar dirname</span><br></pre></td></tr></table></figure><h2 id="gzip-gunzip"><a href="#gzip-gunzip" class="headerlink" title="gzip / gunzip"></a><a href="https://man.linuxde.net/gzip" target="_blank" rel="noopener">gzip</a> / <a href="https://man.linuxde.net/gunzip" target="_blank" rel="noopener">gunzip</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">解压1：gunzip filename.gz  # 不保留原文件</span><br><span class="line">解压1：gunzip –c filename.gz &gt; filename # 保留原文件</span><br><span class="line">解压2：gzip -d filename.gz</span><br><span class="line"></span><br><span class="line">压缩1：gzip filename / gzip -r dirname  # 不保留原文件</span><br><span class="line">压缩2：gzip –c filename &gt; filename.gz # 保留原文件</span><br></pre></td></tr></table></figure><h2 id="bzip2-bunzip2"><a href="#bzip2-bunzip2" class="headerlink" title="bzip2 / bunzip2"></a><a href="https://man.linuxde.net/bzip2" target="_blank" rel="noopener">bzip2</a> / <a href="https://man.linuxde.net/bunzip2" target="_blank" rel="noopener">bunzip2</a></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">解压1：bzip2 -d filename.bz2 # 不保留原文件</span><br><span class="line">解压1：bzip2 -d -k filename.bz2 # 保留原文件</span><br><span class="line">解压2：bunzip2 filename.bz2</span><br><span class="line"></span><br><span class="line">压缩：bzip2 filename  # -k 保留原文件</span><br><span class="line">压缩：bzip2 -z filename  # 强制压缩</span><br></pre></td></tr></table></figure><h2 id="rar"><a href="#rar" class="headerlink" title="rar"></a>rar</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">压缩：rar a -r experiment.rar ~/experiment/</span><br><span class="line">解压：rar x experment.rar ~/test/　# 将文件 experiment.rar 文件解压至指定的文件夹</span><br></pre></td></tr></table></figure><h1 id="Python读取压缩文件"><a href="#Python读取压缩文件" class="headerlink" title="Python读取压缩文件"></a>Python读取压缩文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import gzip</span><br><span class="line">fr = gzip.open(&apos;xxx.gz&apos;, &apos;r&apos;)</span><br><span class="line">line = fr.readline().decode(&apos;utf8&apos;)</span><br><span class="line"></span><br><span class="line">import bz2</span><br><span class="line">fr = bz2.BZ2File(&apos;xxx.bz2&apos;, &apos;r&apos;)</span><br><span class="line"></span><br><span class="line">import zipfile</span><br><span class="line">fr = zipfile.ZipFile(&quot;xxx.zip&quot;, &quot;r&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;解压缩命令&quot;&gt;&lt;a href=&quot;#解压缩命令&quot; class=&quot;headerlink&quot; title=&quot;解压缩命令&quot;&gt;&lt;/a&gt;解压缩命令&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;后缀：&lt;code&gt;.zip&lt;/code&gt;, &lt;code&gt;.tar&lt;/code&gt;, &lt;code&gt;.gz&lt;/
      
    
    </summary>
    
      <category term="教程" scheme="http://www.zhuzongkui.top/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="Linux" scheme="http://www.zhuzongkui.top/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>MySQL 安装配置教程（Windows、Linux）</title>
    <link href="http://www.zhuzongkui.top/2019/08/10/mysql/"/>
    <id>http://www.zhuzongkui.top/2019/08/10/mysql/</id>
    <published>2019-08-10T12:05:48.000Z</published>
    <updated>2019-09-06T09:25:17.454Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="MySQL-配置安装教程"><a href="#MySQL-配置安装教程" class="headerlink" title="MySQL 配置安装教程"></a>MySQL 配置安装教程</h1><ul><li><a href="https://cdn.mysql.com//Downloads/MySQL-8.0/mysql-8.0.17-winx64.zip" target="_blank" rel="noopener">MySQL Community Server 8.0.17 下载链接</a></li></ul><h2 id="一、博客教程"><a href="#一、博客教程" class="headerlink" title="一、博客教程"></a>一、博客教程</h2><h3 id="1、Windows-系统安装"><a href="#1、Windows-系统安装" class="headerlink" title="1、Windows 系统安装"></a>1、Windows 系统安装</h3><ul><li><a href="https://blog.csdn.net/qq_20788055/article/details/80372577" target="_blank" rel="noopener">Win10安装mysql-8.0.11-winx64详细步骤</a></li><li><a href="https://blog.csdn.net/lk0328/article/details/88223135" target="_blank" rel="noopener">win10下安装MySQL8小结</a></li><li><a href="https://www.cnblogs.com/raind/p/8977135.html" target="_blank" rel="noopener">windows10+mysql8.0.11zip安装</a></li></ul><h3 id="2、Linux-系统安装"><a href="#2、Linux-系统安装" class="headerlink" title="2、Linux 系统安装"></a>2、Linux 系统安装</h3><ul><li>在线安装：<br><a href="https://www.cnblogs.com/luoli-/p/9249769.html" target="_blank" rel="noopener">ubuntu 安装Mysql 8.0</a> 下载deb包：<a href="https://dev.mysql.com/downloads/repo/apt/" target="_blank" rel="noopener">https://dev.mysql.com/downloads/repo/apt/</a></li><li>离线安装：<br><a href="https://blog.csdn.net/u011133135/article/details/81561061" target="_blank" rel="noopener">ubuntu mysql8.0安装配置过程linux-generic(linux通用版本)</a>、<br><a href="https://blog.51cto.com/13804472/2134479" target="_blank" rel="noopener">如何在Ubuntu Linux上安装 MySQL 8.0.11</a>、<br><a href="https://blog.csdn.net/weixin_40902527/article/details/83618989" target="_blank" rel="noopener">Linux 离线安装mysql8.0</a></li></ul><h3 id="3、MySQL-连接和常用命令"><a href="#3、MySQL-连接和常用命令" class="headerlink" title="3、MySQL 连接和常用命令"></a>3、MySQL 连接和常用命令</h3><ul><li><a href="https://www.runoob.com/python3/python3-mysql.html" target="_blank" rel="noopener">Python3 MySQL 数据库连接 - PyMySQL 驱动</a></li><li><a href="https://www.runoob.com/mysql/mysql-tutorial.html" target="_blank" rel="noopener">MySQL 教程</a></li></ul><h2 id="二、详细操作"><a href="#二、详细操作" class="headerlink" title="二、详细操作"></a>二、详细操作</h2><h3 id="①-Windows"><a href="#①-Windows" class="headerlink" title="① Windows"></a>① Windows</h3><ul><li>1、mysql-8.0.17-winx64.zip 文件解压到D盘根目录，新建配置文件 my.ini，新建数据存储目录 Data/</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## my.ini 文件内容</span></span><br><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="comment"># 设置3306端口</span></span><br><span class="line"><span class="attr">port</span>=<span class="number">3306</span></span><br><span class="line"><span class="comment"># 设置mysql的安装目录</span></span><br><span class="line"><span class="attr">basedir</span>=D:\mysql-<span class="number">8.0</span>.<span class="number">16</span>-winx64</span><br><span class="line"><span class="comment"># 设置mysql数据库的数据的存放目录</span></span><br><span class="line"><span class="attr">datadir</span>=D:\mysql-<span class="number">8.0</span>.<span class="number">16</span>-winx64\Data</span><br><span class="line"><span class="comment"># 允许最大连接数</span></span><br><span class="line"><span class="attr">max_connections</span>=<span class="number">200</span></span><br><span class="line"><span class="comment"># 允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统</span></span><br><span class="line"><span class="attr">max_connect_errors</span>=<span class="number">10</span></span><br><span class="line"><span class="comment"># 服务端使用的字符集默认为UTF8</span></span><br><span class="line"><span class="attr">character-set-server</span>=utf8mb4</span><br><span class="line"><span class="comment"># 创建新表时将使用的默认存储引擎</span></span><br><span class="line"><span class="attr">default-storage-engine</span>=INNODB</span><br><span class="line"><span class="comment"># 默认使用“mysql_native_password”插件认证</span></span><br><span class="line"><span class="attr">default_authentication_plugin</span>=mysql_native_password</span><br><span class="line"><span class="comment">#开启查询缓存</span></span><br><span class="line"><span class="attr">explicit_defaults_for_timestamp</span>=<span class="literal">true</span></span><br><span class="line"><span class="comment">#skip-grant-tables</span></span><br><span class="line"><span class="section">[mysql]</span></span><br><span class="line"><span class="comment"># 设置mysql客户端默认字符集</span></span><br><span class="line"><span class="attr">default-character-set</span>=utf8mb4</span><br><span class="line"><span class="section">[client]</span></span><br><span class="line"><span class="comment"># 设置mysql客户端连接服务端时默认使用的端口</span></span><br><span class="line"><span class="attr">port</span>=<span class="number">3306</span></span><br><span class="line"><span class="attr">default-character-set</span>=utf8mb4</span><br><span class="line"><span class="comment"># 随机初始密码：xxxxxxxxxxxxxx</span></span><br></pre></td></tr></table></figure><ul><li><p>2、配置系统环境变量：D:\mysql-8.0.16-winx64\bin</p></li><li><p>3、数据库初始化</p></li></ul><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysqld --initialize --console      # 会默认生成一个随机初始密码，临时保存一下</span><br><span class="line">mysqld --install                   # 安装</span><br><span class="line"><span class="built_in">net</span> <span class="built_in">start</span> mysql                    # 启动服务</span><br><span class="line"><span class="built_in">net</span> stop mysql                     # 停止服务（不执行）</span><br></pre></td></tr></table></figure><ul><li>4、打开数据库 cmd 进入</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p    # 输入保存的初始密码</span><br><span class="line">ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '新密码';  # 修改数据库密码</span><br><span class="line"></span><br><span class="line"># 常用命令查看数据库信息：</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> 库名;</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">databases</span>;</span><br><span class="line"><span class="keyword">use</span> 库名;</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">tables</span>;</span><br><span class="line">desc 表名；   显示表的信息</span><br><span class="line"><span class="keyword">show</span> <span class="keyword">variables</span> <span class="keyword">like</span> <span class="string">'character%'</span>;   显示编码</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> 表名;</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> 表名;</span><br><span class="line">drop table 表名;  # 删表</span><br></pre></td></tr></table></figure><ul><li>5、Python 访问数据库</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line">read_con = pymysql.connect(host=<span class="string">"localhost"</span>, user=<span class="string">'root'</span>, password=<span class="string">'mysql'</span>, database=<span class="string">'ccks2019'</span>, charset=<span class="string">'utf8mb4'</span>)</span><br><span class="line">cur = read_con.cursor()</span><br><span class="line">sql = <span class="string">"show tables;"</span>   <span class="comment">## sql 命令</span></span><br><span class="line">cur.execute(sql)</span><br><span class="line">data = cur.fetchall()  <span class="comment">## 获取执行的所有结果</span></span><br><span class="line">print(data)</span><br><span class="line">read_con.close()</span><br><span class="line">cur.close()</span><br></pre></td></tr></table></figure><ul><li>6、建立访客用户 <a href="https://blog.csdn.net/li_0891/article/details/80915780" target="_blank" rel="noopener">教程</a></li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">create user 'guest'@'%' identified by '123456';   # 用户名guest，密码123456，%表示任意主机ip</span><br><span class="line">GRANT SELECT ON ccks2019.* TO 'guest'@'%';        # 授权只可以使用 select 权限</span><br><span class="line">mysql -uguest -p123456 -h[远程IP地址] -P3306 -Dccks2019   # 访问远程的 MySQL 数据库</span><br></pre></td></tr></table></figure><h3 id="②-Ubuntu"><a href="#②-Ubuntu" class="headerlink" title="② Ubuntu"></a>② Ubuntu</h3><ul><li>1、离线安装</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf mysql-8.0.12-linux-glibc2.12-x86_64.tar.xz</span><br><span class="line">mv mysql-8.0.12-linux-glibc2.12-x86_64/ mysql</span><br><span class="line">mv mysql/ /usr/<span class="built_in">local</span>/mysql</span><br><span class="line"></span><br><span class="line">groupadd mysql</span><br><span class="line">useradd -r -g mysql -s /bin/<span class="literal">false</span> mysql</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line"><span class="built_in">cd</span> mysql</span><br><span class="line">mkdir mysql-files</span><br><span class="line">sudo chown mysql:mysql mysql-files</span><br><span class="line">sudo chmod 750 mysql-files</span><br><span class="line">bin/mysqld --initialize --user=mysql</span><br><span class="line"><span class="comment"># 如果报错，安装</span></span><br><span class="line">apt-cache search libaio </span><br><span class="line">apt-get install libaio1</span><br><span class="line">./support-files/mysql.server start</span><br></pre></td></tr></table></figure><ul><li>2、环境变量</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">"<span class="variable">$PATH</span>:/usr/local/mysql/bin"</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><ul><li>3、其他命令同 Windows 系统 step4</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;MySQL-配置安装教程&quot;&gt;&lt;a href=&quot;#MySQL-配置安装教程&quot; class=&quot;headerlink&quot; title=&quot;MySQL 配置安装教程&quot;&gt;&lt;/a&gt;MySQL 配置安装教程&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="教程" scheme="http://www.zhuzongkui.top/categories/%E6%95%99%E7%A8%8B/"/>
    
    
      <category term="数据库" scheme="http://www.zhuzongkui.top/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>中文知识图谱问答 CCKS2019 CKBQA - 参赛总结</title>
    <link href="http://www.zhuzongkui.top/2019/08/04/ccks2019_ckbqa/"/>
    <id>http://www.zhuzongkui.top/2019/08/04/ccks2019_ckbqa/</id>
    <published>2019-08-04T08:03:44.000Z</published>
    <updated>2019-09-03T02:00:20.587Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><ul><li>调研时间：2019.06.05~2019.06.19</li><li>参赛时间：2019.06.28~2019.07.25</li></ul><h1 id="中文知识图谱问答（从0到0-6-）"><a href="#中文知识图谱问答（从0到0-6-）" class="headerlink" title="中文知识图谱问答（从0到0.6+）"></a>中文知识图谱问答（从0到0.6+）</h1><ul><li>Chinese Knowledge Base Question Answering（CKBQA）</li></ul><h2 id="一、任务"><a href="#一、任务" class="headerlink" title="一、任务"></a>一、任务</h2><h3 id="1、任务定义"><a href="#1、任务定义" class="headerlink" title="1、任务定义"></a>1、任务定义</h3><h4 id="什么是知识库？"><a href="#什么是知识库？" class="headerlink" title="什么是知识库？"></a>什么是知识库？</h4><ul><li><p>一条条知识，而把大量的知识汇聚起来就成了知识库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ex1：奥巴马出生在火奴鲁鲁</span><br><span class="line">ex2：姚明是中国人</span><br><span class="line">ex3：谢霆锋的爸爸是谢贤</span><br></pre></td></tr></table></figure></li><li><p>知识来源：维基百科、百度百科等百科全书</p></li><li>特点：非结构化的自然语言、不适合计算机去处理</li><li><p>三元组（triple）（为了方便计算机的处理和理解，需要更加形式化、简洁化的方式去表示知识）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">- ex1：奥巴马出生在火奴鲁鲁 --&gt; (奥巴马，出生地，火奴鲁鲁)</span><br><span class="line">- （主语，谓语，宾语）subject predicate object</span><br><span class="line">- （实体，属性，属性值）entity attribute value</span><br><span class="line">- （头实体，关系，尾实体）head_entity relation tail_entity</span><br></pre></td></tr></table></figure></li><li><p>进一步，把实体看作是结点，把关系看作是一条边，包含大量三元组的知识库就构成了一个庞大的知识图谱</p></li></ul><h4 id="什么是知识库问答？"><a href="#什么是知识库问答？" class="headerlink" title="什么是知识库问答？"></a>什么是知识库问答？</h4><ul><li>基于知识库问答（knowledge base question answering, KBQA）</li><li>即，给定自然语言问题，通过对问题进行语义理解和解析，进而利用知识库进行查询、推理得出答案。</li><li>按应用领域划分：开放领域（百科知识问答等）和特定领域（金融、医疗、宗教、客服等）</li><li>评价指标：召回率、精确率、F1值、MRR（平均倒数排序）<ul><li><script type="math/tex; mode=display">Q\text{为问题集合，}A_i\text{为对第i个问题给出的答案集合，}G_i\text{为第i个问题的标准答案集合}</script></li><li><script type="math/tex; mode=display">Macro Precision = \frac{1}{|Q|} \sum_{i=1}^{|Q|}P_i，P_i = \frac {|A_i \cap G_i|} {|A_i|}</script></li><li><script type="math/tex; mode=display">Macro Recall = \frac{1}{|Q|} \sum_{i=1}^{|Q|}R_i，R_i = \frac {|A_i \cap G_i|} {|G_i|}</script></li><li><script type="math/tex; mode=display">Averaged F1 =  \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{2P_iR_i}{P_i+R_i}</script></li></ul></li><li>两大关键技术<ul><li>【实体链指】：将问句中的实体名字链接到知识库中特定的实体上，涉及到实体识别和实体消歧。</li><li>【关系抽取】：将问句中的实体关系抽取出来，涉及到词性标注、词法句法分析、关系分类等。</li></ul></li><li>举个栗子：姚明的老婆是什么星座？<ul><li>（姚明，妻子，叶莉）—&gt;（叶莉，星座，天蝎）</li></ul></li></ul><h4 id="CCKS2019CKBQA定义"><a href="#CCKS2019CKBQA定义" class="headerlink" title="CCKS2019CKBQA定义"></a>CCKS2019CKBQA定义</h4><ul><li>基于中文知识图谱的自然语言问答，简称 CKBQA<br>（Chinese Knowledge Base Question Answering）</li><li>即输入一句中文问题，问答系统从给定知识库中选择若干实体或属性值作为该问题的答案。</li><li>问题均为客观事实型，不包含主观因素。</li><li>理解并回答问题的过程中可能需要进行实体识别、关系抽取、语义解析等子任务。</li><li>这些子任务的训练可以使用额外的资源，但是最终的答案必须来自给定的知识库。</li></ul><h3 id="2、相关评测"><a href="#2、相关评测" class="headerlink" title="2、相关评测"></a>2、相关评测</h3><h4 id="简单问题：NLPCC-2015-2018-（对应单元组查询）"><a href="#简单问题：NLPCC-2015-2018-（对应单元组查询）" class="headerlink" title="简单问题：NLPCC 2015-2018 （对应单元组查询）"></a>简单问题：<code>NLPCC 2015-2018</code> <code>（对应单元组查询）</code></h4><ul><li><a href="http://tcci.ccf.org.cn/conference/2015/pages/page05_evadata.html" target="_blank" rel="noopener">NLPCC2015 评测：Open Domain Question Answering</a></li><li><a href="http://tcci.ccf.org.cn/conference/2016/pages/page05_evadata.html" target="_blank" rel="noopener">NLPCC2016 评测：Open Domain Chinese Question Answering</a></li><li><a href="http://tcci.ccf.org.cn/conference/2017/taskdata.php" target="_blank" rel="noopener">NLPCC2017 评测：Open Domain Question Answering</a></li><li><a href="http://tcci.ccf.org.cn/conference/2018/taskdata.php" target="_blank" rel="noopener">NLPCC2018 评测：Open Domain Question Answering</a></li></ul><h4 id="复杂问题：CCKS-2018-2019-（对应多元组查询）"><a href="#复杂问题：CCKS-2018-2019-（对应多元组查询）" class="headerlink" title="复杂问题：CCKS  2018-2019 （对应多元组查询）"></a>复杂问题：<code>CCKS  2018-2019</code> <code>（对应多元组查询）</code></h4><ul><li><a href="http://www.ccks2018.cn/?page_id=16" target="_blank" rel="noopener">CCKS2018 评测 任务四：开放领域的中文问答任务</a>，<a href="https://biendata.com/competition/CCKS2018_4/" target="_blank" rel="noopener">CCKS2018 COQA 比赛平台</a></li><li><a href="http://www.ccks2019.cn/?page_id=62" target="_blank" rel="noopener">CCKS2019 评测 任务六：中文知识图谱问答</a>，<a href="https://biendata.com/competition/ccks_2019_6/" target="_blank" rel="noopener">CCKS2019 CKBQA 比赛平台</a>，<a href="http://pkubase.gstore-pku.com/" target="_blank" rel="noopener">PKU BASE的在线查询终端：gStore</a>，<a href="https://www.w3.org/TR/rdf-sparql-query/" target="_blank" rel="noopener">SPARQL语法规则</a></li></ul><h3 id="3、相关数据"><a href="#3、相关数据" class="headerlink" title="3、相关数据"></a>3、相关数据</h3><h4 id="训练集"><a href="#训练集" class="headerlink" title="训练集"></a>训练集</h4><h5 id="NLPCC-2016（14609条）2016、2018测试集答案"><a href="#NLPCC-2016（14609条）2016、2018测试集答案" class="headerlink" title="NLPCC 2016（14609条）2016、2018测试集答案"></a>NLPCC 2016（14609条）<a href="https://github.com/msra-nlc/ChineseKBQA" target="_blank" rel="noopener">2016、2018测试集答案</a></h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;question id=1&gt;《机械设计基础》这本书的作者是谁？</span><br><span class="line">&lt;answer id=1&gt;杨可桢，程光蕴，李仲生</span><br><span class="line">==================================================</span><br><span class="line">&lt;question id=2&gt;《高等数学》是哪个出版社出版的？</span><br><span class="line">&lt;answer id=2&gt;武汉大学出版社</span><br><span class="line">==================================================</span><br></pre></td></tr></table></figure><h5 id="CCKS-2019-（2298条）"><a href="#CCKS-2019-（2298条）" class="headerlink" title="CCKS 2019 （2298条）"></a>CCKS 2019 （2298条）</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">q1:莫妮卡·贝鲁奇的代表作？</span><br><span class="line">select ?x where &#123; &lt;莫妮卡·贝鲁奇&gt; &lt;代表作品&gt; ?x. &#125;</span><br><span class="line">&lt;西西里的美丽传说&gt;</span><br><span class="line"></span><br><span class="line">q2:《湖上草》是谁的诗？</span><br><span class="line">select ?x where &#123; ?x &lt;主要作品&gt; &lt;湖上草&gt;. &#125;</span><br><span class="line">&lt;柳如是_（明末&quot;秦淮八艳&quot;之一）&gt;</span><br></pre></td></tr></table></figure><h4 id="知识库"><a href="#知识库" class="headerlink" title="知识库"></a>知识库</h4><h5 id="NLPCC-2016-知识库网盘"><a href="#NLPCC-2016-知识库网盘" class="headerlink" title="NLPCC 2016 知识库网盘"></a>NLPCC 2016 <a href="https://pan.baidu.com/s/1dEYcQXz" target="_blank" rel="noopener">知识库网盘</a></h5><ul><li><p>三元组（43063796条）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">空气干燥 ||| 别名 ||| 空气干燥</span><br><span class="line">空气干燥 ||| 中文名 ||| 空气干燥</span><br><span class="line">空气干燥 ||| 外文名 ||| air drying</span><br><span class="line">空气干燥 ||| 形式 ||| 两个</span><br><span class="line">空气干燥 ||| 作用 ||| 将空气中的水份去除</span><br></pre></td></tr></table></figure></li><li><p>提及-实体（7623034条）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">空气 干燥 ||| 空气干燥</span><br><span class="line">air drying ||| 空气干燥 氧化结膜干燥</span><br><span class="line">罗育德 ||| 罗育德</span><br><span class="line">鳞 ||| 鳞       公子鳞</span><br><span class="line">squama ||| 鳞   鳞片</span><br></pre></td></tr></table></figure></li></ul><h5 id="CCKS-2019-知识库网盘，密码：hcu8-开放领域问答的数据-金融领域问答数据-1-4"><a href="#CCKS-2019-知识库网盘，密码：hcu8-开放领域问答的数据-金融领域问答数据-1-4" class="headerlink" title="CCKS 2019 知识库网盘，密码：hcu8 开放领域问答的数据+金融领域问答数据 (1/4)"></a>CCKS 2019 <a href="https://pan.baidu.com/s/1MOv9PCTcALVIiodUP4bQ2Q" target="_blank" rel="noopener">知识库网盘，密码：hcu8</a> 开放领域问答的数据+金融领域问答数据 (1/4)</h5><ul><li><p>三元组（41009142条）：由&lt;&gt;括起的为实体，由””括起的为文本值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;公司名称&gt;      &quot;美国奥可斯（香港）国际控股集团有限公司&quot; .</span><br><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;成立时间&gt;      &quot;2007-06-28&quot; .</span><br><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;经营范围&gt;      &lt;培训&gt; .</span><br><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;经营范围&gt;      &lt;影视&gt; .</span><br><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;公司口号&gt;      &quot;品牌立业，质量最好&quot; .</span><br></pre></td></tr></table></figure></li><li><p>提及 + 实体 + order（13930118条）：可以用来辅助选手进行实体链接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">献陵    献陵_（唐高祖李渊陵墓） 1</span><br><span class="line">献陵    明献陵  2</span><br><span class="line">献陵    献陵_（朝鲜太宗献陵）   3</span><br><span class="line">佛罗伦萨        佛罗伦萨_（意大利托斯卡纳大区首府）     1</span><br><span class="line">佛罗伦萨        佛罗伦萨足球俱乐部      2</span><br></pre></td></tr></table></figure></li><li><p>实体 + 类型 + 值（25182628条）：可以用于检查问题类型和答案类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;类型&gt;  &lt;文学作品&gt; .</span><br><span class="line">&lt;美国奥可斯（香港）国际控股集团&gt;        &lt;类型&gt;  &lt;文化&gt; .</span><br><span class="line">&lt;寻美中国&gt;      &lt;类型&gt;  &lt;品牌&gt; .</span><br><span class="line">&lt;青春是我和你一杯酒的深&gt;        &lt;类型&gt;  &lt;文学作品&gt; .</span><br><span class="line">&lt;青春是我和你一杯酒的深&gt;        &lt;类型&gt;  &lt;网络小说&gt; .</span><br></pre></td></tr></table></figure></li></ul><h3 id="4、相关工作"><a href="#4、相关工作" class="headerlink" title="4、相关工作"></a>4、相关工作</h3><ul><li>NLPCC2015 第1名评测论文 [1]</li><li>NLPCC2016 第1-4名评测论文 [2-5]</li><li>NLPCC2017 第1-2名评测论文 + 会议论文 [6-8]</li><li>NLPCC2018 第1名评测论文 [9]</li><li>CCKS2018  第1-3名评测论文 [10-12]</li><li>CCKS2019  第1-4名评测论文 [13-16]</li></ul><h2 id="二、方法"><a href="#二、方法" class="headerlink" title="二、方法"></a>二、方法</h2><h3 id="1、创建数据库"><a href="#1、创建数据库" class="headerlink" title="1、创建数据库"></a>1、创建数据库</h3><ul><li>图数据库：NEO4J、JENA、gStore（Linux）</li><li>关系数据库：MySQL（<a href="http://www.zhuzongkui.top/2019/08/10/MySQL_Config">ours</a>）、PostgreSQL</li><li>注意：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">统计字段长度</span><br><span class="line">检查数据正误</span><br><span class="line">设置主键：id 自增</span><br><span class="line">创建索引</span><br><span class="line">设置编码：utf8mb4</span><br><span class="line">设置引擎：Innodb</span><br><span class="line">建立访客用户</span><br><span class="line">Python - pymysql</span><br></pre></td></tr></table></figure></li></ul><h3 id="2、创建训练数据"><a href="#2、创建训练数据" class="headerlink" title="2、创建训练数据"></a>2、创建训练数据</h3><h4 id="分类单多跳问句（二分类）"><a href="#分类单多跳问句（二分类）" class="headerlink" title="分类单多跳问句（二分类）"></a>分类单多跳问句（二分类）</h4><ul><li><p>单跳：<code>SPARQL 只出现一个三元组</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q1:莫妮卡·贝鲁奇的代表作？</span><br><span class="line">select ?x where &#123; &lt;莫妮卡·贝鲁奇&gt; &lt;代表作品&gt; ?x. &#125;</span><br><span class="line">&lt;西西里的美丽传说&gt;</span><br></pre></td></tr></table></figure></li><li><p>双跳：<code>SPARQL 出现两个以上三元组</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q616:红豆的演唱者出生在？</span><br><span class="line">select ?y where &#123; ?x &lt;代表作品&gt; &lt;红豆_（王菲演唱歌曲）&gt;. ?x &lt;出生地&gt; ?y. &#125;</span><br><span class="line">&lt;东城区_（北京市东城区）&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="分类链式问句（二分类）"><a href="#分类链式问句（二分类）" class="headerlink" title="分类链式问句（二分类）"></a>分类链式问句（二分类）</h4><ul><li>链式：<code>SPARQL 多个三元组呈递进关系，x-&gt;y-&gt;z，非交集关系</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">q894:纳兰性德的父亲担任过什么官职？</span><br><span class="line">select ?y where &#123; &lt;纳兰性德&gt; &lt;父亲&gt; ?x. ?x &lt;主要职位&gt; ?y. &#125;</span><br><span class="line">&quot;武英殿大学士&quot;&quot;太子太傅&quot;</span><br><span class="line"></span><br><span class="line">q554:宗馥莉任董事长的公司的公司口号是？</span><br><span class="line">select ?y where &#123; ?x &lt;董事长&gt; &lt;宗馥莉&gt;. ?x &lt;公司口号&gt; ?y. &#125;</span><br><span class="line">&quot;win happy health,娃哈哈就在你身边&quot;</span><br></pre></td></tr></table></figure></li></ul><h4 id="主谓宾分类（三分类）"><a href="#主谓宾分类（三分类）" class="headerlink" title="主谓宾分类（三分类）"></a>主谓宾分类（三分类）</h4><ul><li><p>问句的答案对应三元组里面的主语，spo=0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q70:《悼李夫人赋》是谁的作品？</span><br><span class="line">select ?x where &#123; ?x &lt;代表作品&gt; &lt;悼李夫人赋&gt;. &#125;</span><br><span class="line">&lt;汉武帝_（汉朝皇帝）&gt;</span><br></pre></td></tr></table></figure></li><li><p>问句的答案对应三元组里面的谓语，spo=1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q506:林徽因和梁思成是什么关系？</span><br><span class="line">select ?x where &#123; &lt;林徽因_（中国建筑师、诗人、作家）&gt; ?x &lt;梁思成&gt;. &#125;</span><br><span class="line">&lt;丈夫&gt;</span><br></pre></td></tr></table></figure></li><li><p>问句的答案对应三元组里面的宾语，spo=2</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">q458:天津大学的现任校长是谁？</span><br><span class="line">select ?x where &#123; &lt;天津大学&gt; &lt;现任校长&gt; ?x . &#125;</span><br><span class="line">&lt;李家俊_（天津市委委员，天津大学校长）&gt;</span><br></pre></td></tr></table></figure></li></ul><h4 id="实体提及识别（NER序列标注）"><a href="#实体提及识别（NER序列标注）" class="headerlink" title="实体提及识别（NER序列标注）"></a>实体提及识别（NER序列标注）</h4><ul><li>根据训练语料的SPARQL语句，查找实体的提及，反向构建训练数据<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">q1408:电影《怦然心动》的主要演员？</span><br><span class="line">select ?x where &#123; &lt;怦然心动_（美国2010年罗伯·莱纳执导电影）&gt; &lt;主演&gt; ?x. &#125;</span><br><span class="line">&lt;艾丹·奎因&gt;&lt;玛德琳·卡罗尔&gt;&lt;卡兰·麦克奥利菲&gt;&lt;约翰·玛哈尼&gt;&lt;摩根·莉莉&gt;</span><br><span class="line"></span><br><span class="line">电 O</span><br><span class="line">影 O</span><br><span class="line">《 O</span><br><span class="line">怦 B-LOC</span><br><span class="line">然 I-LOC</span><br><span class="line">心 I-LOC</span><br><span class="line">动 I-LOC</span><br><span class="line">》 O</span><br><span class="line">的 O</span><br><span class="line">主 O</span><br><span class="line">要 O</span><br><span class="line">演 O</span><br><span class="line">员 O</span><br><span class="line">？ O</span><br></pre></td></tr></table></figure></li></ul><h4 id="关系抽取（语义相似度计算，二分类）"><a href="#关系抽取（语义相似度计算，二分类）" class="headerlink" title="关系抽取（语义相似度计算，二分类）"></a>关系抽取（语义相似度计算，二分类）</h4><ul><li>查找实体的关系中与问句最相近的关系</li><li>一个正例，再从对应实体的关系中随机抽取5个作为负例<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">q267:里奥·梅西的生日是什么时候？</span><br><span class="line">select ?x where &#123; &lt;里奥·梅西_（阿根廷足球运动员）&gt; &lt;出生日期&gt; ?x . &#125;</span><br><span class="line">&quot;1987-06-24&quot;</span><br><span class="line"></span><br><span class="line">里奥·梅西的生日是什么时候？出生日期1</span><br><span class="line">里奥·梅西的生日是什么时候？妻子0</span><br><span class="line">里奥·梅西的生日是什么时候？所属运动队0</span><br><span class="line">里奥·梅西的生日是什么时候？中文名0</span><br><span class="line">里奥·梅西的生日是什么时候？类型0</span><br><span class="line">里奥·梅西的生日是什么时候？外文名0</span><br></pre></td></tr></table></figure></li></ul><h4 id="实体链接（二分类）"><a href="#实体链接（二分类）" class="headerlink" title="实体链接（二分类）"></a>实体链接（二分类）</h4><ul><li>查找问句中实体提及对应的唯一实体</li><li>6个特征：order、提及初始分、问题和提及字符匹配度、问题和实体语义相似度、问题和实体字符匹配度、问题和实体关系的最大相似度 —&gt; 标签<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">q2035:张三丰创立了什么门派？</span><br><span class="line">select ?x where &#123; &lt;张三丰_（武侠小说人物）&gt; &lt;荣誉&gt; ?x . &#125;</span><br><span class="line">&quot;创立武当派&quot;</span><br><span class="line"></span><br><span class="line">张三丰创立了什么门派？&lt;张三丰_（南宋至明初道士）&gt;1.01.00.430.159784660.60.992574450</span><br><span class="line">张三丰创立了什么门派？&lt;张三丰_（武侠小说人物）&gt;0.91.00.430.971324270.580.996603851</span><br><span class="line">张三丰创立了什么门派？&lt;张三丰_（桌游《英雄杀》中的英雄之一）&gt;0.81.00.430.9208610.380.00071649520</span><br></pre></td></tr></table></figure></li></ul><h4 id="纠正错误标注"><a href="#纠正错误标注" class="headerlink" title="纠正错误标注"></a>纠正错误标注</h4><ul><li>由于时间问题只纠正了一部分</li><li>实体中含多余空格：q10、q149、q490、q559、q723、q1191</li><li>多个三元组未以’.’分割：q65</li><li>实体标注错误：q124、q300、q422、q432、q449、q1699</li><li>关系标注错误：q381<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">q10:北京奥运会的口号是什么？</span><br><span class="line">select ?x where &#123; &lt;2008年北京奥运会 &gt; &lt;口号&gt; ?x. &#125; </span><br><span class="line">&quot;同一个世界，同一个梦想&quot;</span><br><span class="line">修正：</span><br><span class="line">select ?x where &#123; &lt;2008年北京奥运会&gt; &lt;口号&gt; ?x. &#125;</span><br><span class="line"></span><br><span class="line">q124:吉野家创建于什么时候？</span><br><span class="line">select ?x where &#123; &lt;吉野家&gt; &lt;创始时间&gt; ?x. &#125;</span><br><span class="line">&quot;1899&quot;</span><br><span class="line">修正：</span><br><span class="line">select ?x where &#123; &lt;吉野家_（日本牛肉饭店）&gt; &lt;创始时间&gt; ?x. &#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="3、训练模型"><a href="#3、训练模型" class="headerlink" title="3、训练模型"></a>3、训练模型</h3><ul><li><p>分类单多跳问句（二分类：BERT 做单句子分类）acc=89.13%</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># acc低的原因：以下问题实则单跳可以解决</span><br><span class="line">q542:习大大是哪里毕业的？</span><br><span class="line">select ?y where &#123; ?x &lt;别名&gt; &quot;习大大&quot; . ?x &lt;毕业院校&gt; ?y . &#125;</span><br><span class="line">&quot;清华大学&quot;</span><br><span class="line"></span><br><span class="line">q1560:小马哥有哪些主要成就？</span><br><span class="line">select ?y where &#123; ?x &lt;别名&gt;&quot;小马哥&quot;. ?x &lt;主要成就&gt; ?y. &#125;</span><br><span class="line">&quot;改变中国SNS现状&quot;&quot;1998年创立 腾讯公司&quot;&quot;腾讯慈善基金会&quot;</span><br><span class="line"></span><br><span class="line">q1574:习大大什么时候入党？</span><br><span class="line">select ?y where &#123; ?x &lt;别名&gt; &quot;习大大&quot;. ?x &lt;入党时间&gt; ?y . &#125;</span><br><span class="line">&quot;1974&quot;</span><br></pre></td></tr></table></figure></li><li><p>分类单多跳问句（二分类：BERT 做单句子分类）acc=96.15%</p></li><li>主谓宾分类（三分类：BERT 做单句子分类）acc=91.63%</li><li><p>实体提及识别（NER序列标注：BERT+BiLSTM+CRF 的 NER 模型）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">评价指标：召回率 Recall</span><br><span class="line">只使用单跳数据，初始结果 87.28%</span><br><span class="line">改进：</span><br><span class="line">去除提及的书名号和双引号，结果 89.47%，但只能识别0~1个实体提及</span><br><span class="line">加入单多跳所有数据，模型测试结果 88.24%，可以识别出多个提及</span><br></pre></td></tr></table></figure></li><li><p>关系抽取（语义相似度计算，二分类：BERT 做句子对分类）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">单跳数据初始结果83.7%，mask掉实体提及81.06%，</span><br><span class="line">最终模型是混合 nlpcc2016 和 ccks2019 的所有数据</span><br><span class="line">改进：</span><br><span class="line">nlpcc2016数据负例是从关系全集中抽取的，</span><br><span class="line">改成ccks2019从对应实体的所有候选关系中抽取</span><br></pre></td></tr></table></figure></li><li><p>实体链接（二分类：xgboost 做分类）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">正例结果acc：89.15%，按概率分布评价acc：97.34%</span><br><span class="line">改进1：</span><br><span class="line">提及得分：order、1/order、提及初始分、实体长度、实体长度占问题长度比</span><br><span class="line">实体得分：问题和实体的语义相似度、问题和实体后缀的语义相似度、问题和实体后缀的杰卡德系数</span><br><span class="line">关系得分：问题和实体关系的最大相似度，问题和实体关系的最大杰卡德系数</span><br><span class="line">正例结果acc：98.90%，按概率分布评价acc：99.13%，初赛最后一天实现，复赛未能派上用场，很遗憾。</span><br><span class="line"></span><br><span class="line">改进2：</span><br><span class="line">查找所有候选实体，提及左右进行扩展或删减，外加百度百科搜索</span><br><span class="line">实体链接后还是没找到实体，采用暴力搜索，逐个字符匹配</span><br><span class="line">若识别出多个提及，则实体链接也对应多个，但链式问题搜索答案时只使用得分最高的</span><br></pre></td></tr></table></figure></li></ul><h3 id="4、预测数据"><a href="#4、预测数据" class="headerlink" title="4、预测数据"></a>4、预测数据</h3><ul><li>实体提及识别要考虑问句中出现的空格问题<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;&quot;id&quot;: &quot;q1&quot;, &quot;question&quot;: &quot;\&quot;成败一知己，生死两妇人\&quot;所说的人物有什么重大成就？&quot;, &quot;hop&quot;: &quot;1&quot;, &quot;spo&quot;: &quot;2&quot;, &quot;chain&quot;: &quot;1&quot;, &quot;mention_list&quot;: [&quot;成败一知己，生死两妇人&quot;]&#125;</span><br><span class="line">&#123;&quot;id&quot;: &quot;q2&quot;, &quot;question&quot;: &quot;葬于茂陵的皇帝在位于哪段时间？&quot;, &quot;hop&quot;: &quot;1&quot;, &quot;spo&quot;: &quot;0&quot;, &quot;chain&quot;: &quot;1&quot;, &quot;mention_list&quot;: [&quot;茂陵&quot;, &quot;皇帝&quot;]&#125;</span><br><span class="line">&#123;&quot;id&quot;: &quot;q3&quot;, &quot;question&quot;: &quot;\&quot;光武中兴\&quot;说的是哪位皇帝？&quot;, &quot;hop&quot;: &quot;0&quot;, &quot;spo&quot;: &quot;0&quot;, &quot;chain&quot;: &quot;0&quot;, &quot;mention_list&quot;: [&quot;光武中兴&quot;]&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="5、搜索答案"><a href="#5、搜索答案" class="headerlink" title="5、搜索答案"></a>5、搜索答案</h3><!-- ![avatar](https://note.youdao.com/yws/public/resource/5c3200954632da9b39248e5d1d991a43/xmlnote/9E8F6ED978224D93AD264F48586627FF/20400) --><p><img src="https://s2.ax1x.com/2019/08/13/mCohTJ.png" alt="流程图"></p><ul><li><p>注释</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hop=0 表示是单跳问题（如：姚明的女儿是谁？），hop=1 表示是多跳问题（单跳问题仅需一个三元组，多跳需两个以上）</span><br><span class="line">spo=0 表示已知谓宾求主语，spo=1 表示已知主宾求谓语，spo=2表示已知主谓求宾语（如：姚明的女儿是谁？）</span><br><span class="line">chain=0 表示非链式问题，chain= 表示链式问题（如：姚明的女儿的年龄是多少？）</span><br><span class="line">ner 表示用NER模型识别出问句中的实体提及（如：姚明的女儿是谁？ 提及：姚明）</span><br><span class="line">Entity Linking 表示实体链指，找出提及对应的实体（如：姚明的女儿是谁？ 实体：&lt;姚明_（中职联公司董事长兼总经理）&gt;）</span><br><span class="line">Relation Extraction 表示关系抽取，找出问题中关系（如：姚明的女儿是谁？ 关系：&lt;女儿&gt;）</span><br></pre></td></tr></table></figure></li><li><p>详细介绍</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">step1：先对问题进行分类（判断是否单多跳、是否主谓宾、是否链式）和提及识别；</span><br><span class="line">step2：根据识别到的提及，进行左右扩展或删减，搜索所有的候选实体，根据一组特征对候选实体打分排序（实体链接模型），取top1；</span><br><span class="line">step3：根据spo值，搜索实体对应的所有关系，与当前问题计算语义相似度（关系抽取模型），取top1，搜索数据库得到统一单跳问题的求解；</span><br><span class="line">step4：如果是链式且是多跳问题，将step3得到的答案作为实体再进行一遍step3，得到多跳链式问题的求解；</span><br><span class="line">step5：如果是非链式且识别到多个实体，对每个实体搜索数据库，查询对应的所有候选三元组，然后求交集，得到多跳多实体问题的求解。</span><br></pre></td></tr></table></figure></li></ul><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><ul><li>参加完CCKS2019评测会议后再补充 。。。。。。</li></ul><h2 id="四、参考文献"><a href="#四、参考文献" class="headerlink" title="四、参考文献"></a>四、参考文献</h2><ul><li>[1] <a href="http://tcci.ccf.org.cn/conference/2015/papers/246.pdf" target="_blank" rel="noopener">NLPCC2015 1st</a> Ye Z, Jia Z, Yang Y, et al. Research on open domain question answering system[M]//Natural Language Processing and Chinese Computing. Springer, Cham, 2015: 527-540.</li><li>[2] <a href="https://link.springer.com/chapter/10.1007%2F978-3-319-50496-4_65" target="_blank" rel="noopener">NLPCC2016 1st</a> Lai Y, Lin Y, Chen J, et al. Open domain question answering system based on knowledge base[M]//Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016: 722-733.</li><li>[3] <a href="https://link.springer.com/chapter/10.1007/978-3-319-50496-4_86" target="_blank" rel="noopener">NLPCC2016 2nd</a> Yang F, Gan L, Li A, et al. Combining deep learning with information retrieval for question answering[M]//Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016: 917-925.</li><li>[4] <a href="https://link.springer.com/chapter/10.1007/978-3-319-50496-4_25" target="_blank" rel="noopener">NLPCC2016 3rd</a> Xie Z, Zeng Z, Zhou G, et al. Knowledge base question answering based on deep learning models[M]//Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016: 300-311.</li><li>[5] <a href="https://link.springer.com/chapter/10.1007/978-3-319-50496-4_82" target="_blank" rel="noopener">NLPCC2016 4th</a> Wang L, Zhang Y, Liu T. A deep learning approach for question answering over knowledge base[M]//Natural Language Understanding and Intelligent Applications. Springer, Cham, 2016: 885-892.</li><li>[6] <a href="http://tcci.ccf.org.cn/conference/2017/papers/2003.pdf" target="_blank" rel="noopener">NLPCC2017 1st</a> Lai Y, Jia Y, Lin Y, et al. A Chinese question answering system for single-relation factoid questions[C]//National CCF Conference on Natural Language Processing and Chinese Computing. Springer, Cham, 2017: 124-135.</li><li>[7] <a href="http://tcci.ccf.org.cn/conference/2017/papers/2041.pdf" target="_blank" rel="noopener">NLPCC2017 2nd</a> Zhang H, Zhu M, Wang H. A Retrieval-Based Matching Approach to Open Domain Knowledge-Based Question Answering[C]//National CCF Conference on Natural Language Processing and Chinese Computing. Springer, Cham, 2017: 701-711.</li><li>[8] <a href="http://xbna.pku.edu.cn/CN/10.13209/j.0479-8023.2017.155" target="_blank" rel="noopener">NLPCC2017 会议</a> 周博通, 孙承杰, 林磊, et al. 基于LSTM的大规模知识库自动问答[J]. 北京大学学报：自然科学版, 2018.</li><li>[9] <a href="https://link.springer.com/chapter/10.1007/978-3-319-99501-4_35" target="_blank" rel="noopener">NLPCC2018 1st</a> Ni H, Lin L, Xu G. A Relateness-Based Ranking Method for Knowledge-Based Question Answering[C]//CCF International Conference on Natural Language Processing and Chinese Computing. Springer, Cham, 2018: 393-400.</li><li>[10] <a href="http://ceur-ws.org/Vol-2242/" target="_blank" rel="noopener">CCKS2018 1st</a> A QA Search Algorithm based on the Fusion Integration of Text Similarity and Graph Computation</li><li>[11] <a href="http://ceur-ws.org/Vol-2242/" target="_blank" rel="noopener">CCKS2018 2nd</a> A Joint Model of Entity Linking and Predicate Recognition for Knowledge Base Question Answering </li><li>[12] <a href="http://ceur-ws.org/Vol-2242/" target="_blank" rel="noopener">CCKS2018 3rd</a> Semantic Parsing for Multiple-relation Chinese Question Answering </li><li>[13] <a href="https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html" target="_blank" rel="noopener">CCKS2019 1st</a> 混合语义相似度的中文知识图谱问答系统</li><li>[14] <a href="https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html" target="_blank" rel="noopener">CCKS2019 2nd</a> Combining Neural Network Models with Rules for Chinese Knowledge Base Question Answering</li><li>[15] <a href="https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html" target="_blank" rel="noopener">CCKS2019 3rd</a> Multi-Module System for Open Domain Chinese Question Answering over Knowledge Base</li><li>[16] <a href="https://conference.bj.bcebos.com/ccks2019/eval/webpage/index.html" target="_blank" rel="noopener">CCKS2019 4th</a> DUTIR中文开放域知识库问答评测报告</li></ul><h2 id="五、相关博客"><a href="#五、相关博客" class="headerlink" title="五、相关博客"></a>五、相关博客</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/53796189" target="_blank" rel="noopener">基于知识图谱的问答系统入门之—NLPCC2016KBQA数据集</a> 【代码未公开】发布于 2019-01-02，编辑于 2019-05-29</li><li><a href="https://blog.csdn.net/ai_1046067944/article/details/86707784" target="_blank" rel="noopener">问答QA（二）基于BERT的知识库问答实战</a>，<a href="https://github.com/jkszw2014/bert-kbqa-NLPCC2017" target="_blank" rel="noopener">Github：bert-kbqa-NLPCC2017</a>  2019年03月09日 00:12:35</li><li><a href="https://zhuanlan.zhihu.com/p/62946533" target="_blank" rel="noopener">基于BERT的KBQA探索-知乎</a>，<a href="https://blog.csdn.net/qq_38150441/article/details/89402988" target="_blank" rel="noopener">基于BERT的KBQA探索-CSDN</a>，<a href="https://github.com/WenRichard/KBQA-BERT" target="_blank" rel="noopener">Github：KBQA-BERT 代码有点像上面的</a> 发布于 2019-04-19，编辑于 2019-07-03</li><li><a href="https://github.com/huangxiangzhou/NLPCC2016KBQA" target="_blank" rel="noopener">NLPCC2016 KBQA 1st 方案</a></li><li><a href="https://github.com/songlei1994/ccks2018" target="_blank" rel="noopener">CCKS2018 CKBQA 1st 方案</a></li><li><a href="http://blog.openkg.cn/自由讨论-kbqa从入门到放弃-入门篇/" target="_blank" rel="noopener">自由讨论 | KBQA从入门到放弃—入门篇</a></li><li><a href="https://zhuanlan.zhihu.com/p/28553553" target="_blank" rel="noopener">KBQA从入门到放弃 - Part 2 | 每周话题精选 #09</a></li><li><a href="https://blog.csdn.net/u012892939/article/details/79451978" target="_blank" rel="noopener">KBQA 知识库问答领域研究综述（未完待续。。）</a></li><li><a href="https://zhuanlan.zhihu.com/p/34585912" target="_blank" rel="noopener">基于知识库的问答：seq2seq模型实践</a></li><li><a href="https://yzhihao.github.io/2017/07/15/KBQA.html" target="_blank" rel="noopener">KBQA 个人总结</a></li><li><a href="https://zhuanlan.zhihu.com/p/27141786" target="_blank" rel="noopener">揭开知识库问答KB-QA的面纱0·导读篇</a></li><li><a href="http://octopuscoder.github.io/2018/02/04/知识图谱问答总结/" target="_blank" rel="noopener">知识图谱问答总结</a></li><li><a href="https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/78146295" target="_blank" rel="noopener">肖仰华 | 基于知识图谱的问答系统</a></li><li><a href="https://blog.csdn.net/keyue123/article/details/85266355" target="_blank" rel="noopener">基于知识图谱的问答系统(KBQA)</a></li><li><a href="https://blog.csdn.net/u012892939/article/details/79476756" target="_blank" rel="noopener">各类QA问答系统的总结与技术实现（持续更新）</a></li><li><a href="http://pelhans.com/2018/04/28/xiaoxiangkg-note9/" target="_blank" rel="noopener">知识图谱入门 (九)知识问答</a></li><li><a href="https://zhuanlan.zhihu.com/p/27665853" target="_blank" rel="noopener">KBQA: 基于开放域知识库上的QA系统 | 每周一起读</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;调研时间：2019.06.05~2019.06.19&lt;/li&gt;
&lt;li&gt;参赛时间：2019.06.28~2019.07.25&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;中文知识图谱问答（从0到0-6-）&quot;&gt;&lt;a href=&quot;#中文知识图谱问
      
    
    </summary>
    
      <category term="总结" scheme="http://www.zhuzongkui.top/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="NLP" scheme="http://www.zhuzongkui.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>常用的排序算法</title>
    <link href="http://www.zhuzongkui.top/2019/04/17/sort/"/>
    <id>http://www.zhuzongkui.top/2019/04/17/sort/</id>
    <published>2019-04-17T12:50:46.000Z</published>
    <updated>2019-08-04T08:45:31.324Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、复杂度"><a href="#一、复杂度" class="headerlink" title="一、复杂度"></a>一、复杂度</h2><div class="table-container"><table><thead><tr><th>排序方式</th><th>平均T(n)</th><th>最坏T(n)</th><th>最好T(n)</th><th>空间复杂度</th><th>稳定性</th></tr></thead><tbody><tr><td>插入排序</td><td>O(n^2)</td><td>O(n^2)</td><td>O(n)</td><td>O(1)</td><td>稳定</td></tr><tr><td>冒泡排序</td><td>O(n^2)</td><td>O(n^2)</td><td>O(n)</td><td>O(1)</td><td>稳定</td></tr><tr><td>选择排序</td><td>O(n^2)</td><td>O(n^2)</td><td>O(n^2)</td><td>O(1)</td><td>不稳定</td></tr><tr><td>希尔排序</td><td>O(n^1.3)</td><td>O(n^2)</td><td>O(n)</td><td>O(1)</td><td>不稳定</td></tr><tr><td>快速排序</td><td>O(nlogn)</td><td>O(n^2)</td><td>O(nlogn)</td><td>O(logn)</td><td>不稳定</td></tr><tr><td>堆排序</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(1)</td><td>不稳定</td></tr><tr><td>归并排序</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(nlogn)</td><td>O(n)</td><td>稳定</td></tr><tr><td>基数排序</td><td>O(d(n+r))</td><td>O(d(n+r))</td><td>O(d(n+r))</td><td>O(n+rd)</td><td>稳定</td></tr></tbody></table></div><hr><h2 id="二、代码实现"><a href="#二、代码实现" class="headerlink" title="二、代码实现"></a>二、代码实现</h2><h3 id="1、直接插入排序-insert"><a href="#1、直接插入排序-insert" class="headerlink" title="1、直接插入排序 insert"></a>1、直接插入排序 insert</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将 L[i] 插入到已经有序的子序列 L[1 2 ... i-1] 中</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">InsertSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(arr)):</span><br><span class="line">        j = i</span><br><span class="line">        <span class="keyword">while</span> j &gt; <span class="number">0</span> <span class="keyword">and</span> arr[j] &lt; arr[j<span class="number">-1</span>]:</span><br><span class="line">            arr[j], arr[j<span class="number">-1</span>] = arr[j<span class="number">-1</span>], arr[j]</span><br><span class="line">            j -= <span class="number">1</span></span><br></pre></td></tr></table></figure><h3 id="2、冒泡排序-bubble"><a href="#2、冒泡排序-bubble" class="headerlink" title="2、冒泡排序 bubble"></a>2、冒泡排序 bubble</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对相邻的元素两两进行比较，顺序相反则进行交换，这样每一趟最大的元素浮到顶端</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BubbleSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)<span class="number">-1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(len(arr)<span class="number">-1</span>-i):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &gt; arr[j+<span class="number">1</span>]:</span><br><span class="line">                arr[j], arr[j+<span class="number">1</span>] = arr[j+<span class="number">1</span>], arr[j]</span><br></pre></td></tr></table></figure><h3 id="3、简单选择排序-select"><a href="#3、简单选择排序-select" class="headerlink" title="3、简单选择排序 select"></a>3、简单选择排序 select</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第i趟排序从 L[i,i+1,...,n] 中选择关键字最小的元素与 L[i] 比较</span></span><br><span class="line"><span class="comment"># 每一趟从待排序的数据元素中选择最小的元素作为首元素</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">SelectSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(arr)<span class="number">-1</span>):</span><br><span class="line">        minv = i</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(arr)):</span><br><span class="line">            <span class="keyword">if</span> arr[j] &lt; arr[minv]:</span><br><span class="line">                minv = j</span><br><span class="line">        <span class="keyword">if</span> minv != i:</span><br><span class="line">            arr[minv], arr[i] = arr[i], arr[minv]</span><br></pre></td></tr></table></figure><h3 id="4、希尔排序-shell（跳着插入排序）"><a href="#4、希尔排序-shell（跳着插入排序）" class="headerlink" title="4、希尔排序 shell（跳着插入排序）"></a>4、希尔排序 shell（跳着插入排序）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">距离为 di 的记录放在同一个组中，进行直接插入排序</span><br><span class="line">di = <span class="number">4</span>, <span class="number">2</span>, <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ShellSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    step = len(arr) / <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> step &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(step, len(arr)):  <span class="comment"># 插入排序</span></span><br><span class="line">            j = i</span><br><span class="line">            <span class="keyword">while</span> j &gt;= step <span class="keyword">and</span> arr[j] &lt; arr[j-step]:</span><br><span class="line">                arr[j], arr[j-step] = arr[j-step], arr[j]</span><br><span class="line">                j -= step</span><br><span class="line">        step = step / <span class="number">2</span></span><br></pre></td></tr></table></figure><h3 id="5、快速排序-quick"><a href="#5、快速排序-quick" class="headerlink" title="5、快速排序 quick"></a>5、快速排序 quick</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">待排序表 L[<span class="number">1</span>,<span class="number">2</span>,...,n] 中任取一个元素 pivot 作为基准或枢纽，</span><br><span class="line">将表划分成两部分，一部分小于 pivot，一部分大于或等于 pivot</span><br><span class="line">L[<span class="number">1</span>,<span class="number">2</span>,...,k<span class="number">-1</span>] 和 L[k+<span class="number">1</span>,...,n] , L[k] = pivot</span><br><span class="line"></span><br><span class="line">操作：</span><br><span class="line">以当前表中第一个元素作为枢纽，对表进行划分</span><br><span class="line">将表中比枢纽值大的元素向右移动，小的向左移动</span><br><span class="line">移动采用从两端往中间夹入的方式（可用于求n个元素中第k小的元素）</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Partition</span><span class="params">(arr, begin, end)</span>:</span>  <span class="comment"># 划分元素</span></span><br><span class="line">    pivot = arr[begin]  <span class="comment"># 选取第一个元素作为基准</span></span><br><span class="line">    left = begin + <span class="number">1</span></span><br><span class="line">    right = end</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        <span class="keyword">while</span> left &lt;= right <span class="keyword">and</span> arr[left] &lt;= pivot:</span><br><span class="line">            left += <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> left &lt;= right <span class="keyword">and</span> arr[right] &gt;= pivot:</span><br><span class="line">            right -= <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> left &lt; right:</span><br><span class="line">            arr[left], arr[right] = arr[right], arr[left]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    arr[begin], arr[right] = arr[right], pivot <span class="comment"># 划分元素放到中间位置</span></span><br><span class="line">    <span class="keyword">return</span> right  <span class="comment"># 返回划分元素的下标</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">QuickSort</span><span class="params">(arr, begin, end)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> begin &lt; end:</span><br><span class="line">        k = Partition(arr, begin, end)</span><br><span class="line">        Partition(arr, begin, k<span class="number">-1</span>)</span><br><span class="line">        Partition(arr, k+<span class="number">1</span>, end)</span><br></pre></td></tr></table></figure><h3 id="6、堆排序-heap-sort"><a href="#6、堆排序-heap-sort" class="headerlink" title="6、堆排序 heap sort"></a>6、堆排序 heap sort</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">大顶堆（完全二叉树）：子节点小于父节点</span><br><span class="line">建堆 A[<span class="number">0</span>,<span class="number">2</span>,...,n<span class="number">-1</span>]，移除根节点，将A[<span class="number">0</span>]与A[n<span class="number">-1</span>]交换，</span><br><span class="line">做最大堆调整的递归运算，建堆 A[<span class="number">0</span>,<span class="number">2</span>,...,n<span class="number">-2</span>]，将A[<span class="number">0</span>]与A[n<span class="number">-2</span>]交换，</span><br><span class="line">直到 A[<span class="number">0</span>]与A[<span class="number">1</span>]交换</span><br><span class="line">思想可用于求大量元素中最小的或最大的几个元素</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MaxHeap_adjust</span><span class="params">(arr, low, high)</span>:</span></span><br><span class="line">    tmp = arr[low]  <span class="comment"># 父节点</span></span><br><span class="line">    <span class="keyword">while</span> <span class="number">2</span> * low + <span class="number">1</span> &lt;= high:</span><br><span class="line">        child = <span class="number">2</span> * low + <span class="number">1</span>  <span class="comment"># 左子节点</span></span><br><span class="line">        <span class="keyword">if</span> child &lt; high <span class="keyword">and</span> arr[child] &lt; arr[child+<span class="number">1</span>]:</span><br><span class="line">            child += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> arr[child] &lt; tmp:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        arr[low] = arr[child]</span><br><span class="line">        low = child</span><br><span class="line">    arr[low] = tmp</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MaxHeapSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    n = len(arr)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n/<span class="number">2</span><span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>):  <span class="comment"># 从下往上调</span></span><br><span class="line">        MaxHeap_adjust(arr, i, n<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):</span><br><span class="line">        arr[i], arr[<span class="number">0</span>] = arr[<span class="number">0</span>], arr[i]  <span class="comment"># 最大值放最后面</span></span><br><span class="line">        MaxHeap_adjust(arr, <span class="number">0</span>, i<span class="number">-1</span>)  <span class="comment"># 重新调整一下</span></span><br></pre></td></tr></table></figure><h3 id="7、二路归并排序-merge（分治）"><a href="#7、二路归并排序-merge（分治）" class="headerlink" title="7、二路归并排序 merge（分治）"></a>7、二路归并排序 merge（分治）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">n 个记录看成是 n 个有序的子表，两两归并，得到 n/<span class="number">2</span> 个有序表，再归并</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Merge</span><span class="params">(left, right)</span>:</span></span><br><span class="line">    i, j = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    res = []  <span class="comment"># 缺点：需要辅助空间</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; len(left) <span class="keyword">and</span> j &lt; len(right):</span><br><span class="line">        <span class="keyword">if</span> left[i] &lt;= right[j]:</span><br><span class="line">            res.append(left[i])</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res.append(right[j])</span><br><span class="line">            j += <span class="number">1</span></span><br><span class="line">    res += left[i:] <span class="keyword">if</span> i &lt; len(left) <span class="keyword">else</span> right[j:]</span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MergeSort</span><span class="params">(arr)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(arr) &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> arr</span><br><span class="line">    middle = len(arr) / <span class="number">2</span></span><br><span class="line">    left = MergeSort(arr[:middle])</span><br><span class="line">    right = MergeSort(arr[middle:])</span><br><span class="line">    <span class="keyword">return</span> Merge(left, right)</span><br></pre></td></tr></table></figure><h3 id="8、基数排序-radix（桶排序）"><a href="#8、基数排序-radix（桶排序）" class="headerlink" title="8、基数排序 radix（桶排序）"></a>8、基数排序 radix（桶排序）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">对数字最高位优先和最低位优先进行排序</span><br><span class="line">例如：先按个位从小到大，再按十位从小到大，再按百位从小到大</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、复杂度&quot;&gt;&lt;a href=&quot;#一、复杂度&quot; class=&quot;headerlink&quot; title=&quot;一、复杂度&quot;&gt;&lt;/a&gt;一、复杂度&lt;/h2&gt;&lt;div class=&quot;table-container&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;排序方式&lt;/
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="数据结构" scheme="http://www.zhuzongkui.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
      <category term="算法" scheme="http://www.zhuzongkui.top/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>安装 cuda、cudnn、nvidia 驱动</title>
    <link href="http://www.zhuzongkui.top/2019/04/17/cuda/"/>
    <id>http://www.zhuzongkui.top/2019/04/17/cuda/</id>
    <published>2019-04-17T10:47:56.000Z</published>
    <updated>2019-08-04T08:45:31.323Z</updated>
    
    <content type="html"><![CDATA[<h2 id="〇、TensorFlow-与-cuda-的对应版本"><a href="#〇、TensorFlow-与-cuda-的对应版本" class="headerlink" title="〇、TensorFlow 与 cuda 的对应版本"></a>〇、TensorFlow 与 cuda 的对应版本</h2><ul><li>官方链接：<a href="https://tensorflow.google.cn/install/source" target="_blank" rel="noopener">https://tensorflow.google.cn/install/source</a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">版本                Python 版本     编译器   编译工具      cuDNNCUDA</span><br><span class="line">tensorflow_gpu-1.13.02.7、3.3-3.6GCC 4.8Bazel 0.19.27.410.0</span><br><span class="line">tensorflow_gpu-1.12.02.7、3.3-3.6GCC 4.8Bazel 0.15.079</span><br><span class="line">tensorflow_gpu-1.11.02.7、3.3-3.6GCC 4.8Bazel 0.15.079</span><br><span class="line">tensorflow_gpu-1.10.02.7、3.3-3.6GCC 4.8Bazel 0.15.079</span><br><span class="line">tensorflow_gpu-1.9.02.7、3.3-3.6GCC 4.8Bazel 0.11.079</span><br><span class="line">tensorflow_gpu-1.8.02.7、3.3-3.6GCC 4.8Bazel 0.10.079</span><br><span class="line">tensorflow_gpu-1.7.02.7、3.3-3.6GCC 4.8Bazel 0.9.079</span><br><span class="line">tensorflow_gpu-1.6.02.7、3.3-3.6GCC 4.8Bazel 0.9.079</span><br><span class="line">tensorflow_gpu-1.5.02.7、3.3-3.6GCC 4.8Bazel 0.8.079</span><br><span class="line">tensorflow_gpu-1.4.02.7、3.3-3.6GCC 4.8Bazel 0.5.468</span><br><span class="line">tensorflow_gpu-1.3.02.7、3.3-3.6GCC 4.8Bazel 0.4.568</span><br><span class="line">tensorflow_gpu-1.2.02.7、3.3-3.6GCC 4.8Bazel 0.4.55.18</span><br><span class="line">tensorflow_gpu-1.1.02.7、3.3-3.6GCC 4.8Bazel 0.4.25.18</span><br><span class="line">tensorflow_gpu-1.0.02.7、3.3-3.6GCC 4.8Bazel 0.4.25.18</span><br></pre></td></tr></table></figure></li></ul><hr><h2 id="一、查看版本"><a href="#一、查看版本" class="headerlink" title="一、查看版本"></a>一、查看版本</h2><h3 id="1、查看-cuda-版本"><a href="#1、查看-cuda-版本" class="headerlink" title="1、查看 cuda 版本"></a>1、查看 cuda 版本</h3><ul><li>cat /usr/local/cuda/version.txt</li><li>nvcc -V</li></ul><h3 id="2、查看-cudnn-版本"><a href="#2、查看-cudnn-版本" class="headerlink" title="2、查看 cudnn 版本"></a>2、查看 cudnn 版本</h3><ul><li>cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2</li><li>cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2</li></ul><h3 id="3、查看显卡驱动版本"><a href="#3、查看显卡驱动版本" class="headerlink" title="3、查看显卡驱动版本"></a>3、查看显卡驱动版本</h3><ul><li>cat /proc/driver/nvidia/version</li><li>nvidia-smi</li></ul><h2 id="二、安装"><a href="#二、安装" class="headerlink" title="二、安装"></a>二、安装</h2><h3 id="1、安装cuda"><a href="#1、安装cuda" class="headerlink" title="1、安装cuda"></a>1、安装cuda</h3><ul><li><a href="https://www.cnblogs.com/iloveblog/p/7683349.html" target="_blank" rel="noopener">Ubuntu16.04+cuda9.0安装教程</a></li><li>下载链接：<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="noopener">https://developer.nvidia.com/cuda-toolkit-archive</a></li><li>执行命令：<code>sudo sh cuda_9.0.176_384.81_linux.run</code> ，不要安装驱动</li><li>配置系统环境变量：<code>sudo vim /etc/profile</code> 或者用户环境变量：<code>vim ~/.bashrc</code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export  PATH=/usr/local/cuda-9.0/bin:$PATH</span><br><span class="line">export  LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64$LD_LIBRARY_PATH</span><br><span class="line"></span><br><span class="line"># 系统环境变量可能要重启电脑 `sudo reboot`</span><br></pre></td></tr></table></figure></li></ul><h3 id="2、安装nvidia驱动"><a href="#2、安装nvidia驱动" class="headerlink" title="2、安装nvidia驱动"></a>2、安装nvidia驱动</h3><ul><li>列出所有可用的 NVIDIA 设备信息：<code>nvidia-smi -L</code></li><li>查找适配自己电脑GPU的驱动：<a href="http://www.nvidia.cn/Download/index.aspx?lang=cn" target="_blank" rel="noopener">http://www.nvidia.cn/Download/index.aspx?lang=cn</a></li><li><a href="https://blog.csdn.net/u012897374/article/details/79966794" target="_blank" rel="noopener">解决nvidia升级驱动后版本匹配问题</a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get purge nvidia*</span><br><span class="line">sudo add-apt-repository ppa:graphics-drivers/ppa</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install nvidia-384 nvidia-settings</span><br><span class="line">reboot</span><br><span class="line">注：如果要是不行，可能需要在bios里将显卡先设置成CPU集卡</span><br><span class="line">验证</span><br><span class="line">1.输入nvidia-smi查看</span><br><span class="line">2.prime-select query查看当前选用的显卡</span><br></pre></td></tr></table></figure></li></ul><h3 id="3、安装cudnn"><a href="#3、安装cudnn" class="headerlink" title="3、安装cudnn"></a>3、安装cudnn</h3><ul><li>下载链接：<a href="https://developer.nvidia.com/rdp/cudnn-archive" target="_blank" rel="noopener">https://developer.nvidia.com/rdp/cudnn-archive</a></li><li><p>执行命令拷贝文件，后者用软连接</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf cudnn-9.0-linux-x64-v7.1.tgz</span><br><span class="line">sudo cp cuda/include/cudnn.h /usr/local/cuda/include/ </span><br><span class="line">sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64/ -d </span><br><span class="line">sudo chmod a+r /usr/local/cuda/include/cudnn.h </span><br><span class="line">sudo chmod a+r /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure></li><li><p>配置系统环境变量：<code>sudo vim /etc/profile</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/usr/local/cuda/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</span><br><span class="line">export CUDA_HOME=/usr/local/cuda</span><br></pre></td></tr></table></figure></li><li><p>刷新环境变量：<code>source /etc/profile</code></p></li></ul><h2 id="三、卸载"><a href="#三、卸载" class="headerlink" title="三、卸载"></a>三、卸载</h2><h3 id="卸载-cuda"><a href="#卸载-cuda" class="headerlink" title="卸载 cuda"></a>卸载 cuda</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/cuda/bin</span><br><span class="line">sudo ./uninstall_cuda_8.0.pl</span><br><span class="line">cd /usr/local</span><br><span class="line">sudo rm -rf cuda-8.0</span><br></pre></td></tr></table></figure><h2 id="四、相关链接"><a href="#四、相关链接" class="headerlink" title="四、相关链接"></a>四、相关链接</h2><h3 id="官方教程"><a href="#官方教程" class="headerlink" title="官方教程"></a><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#handle-uninstallation" target="_blank" rel="noopener">官方教程</a></h3><h3 id="cuda、cudnn、驱动版本查看及nvidia驱动、cuda安装及卸载"><a href="#cuda、cudnn、驱动版本查看及nvidia驱动、cuda安装及卸载" class="headerlink" title="cuda、cudnn、驱动版本查看及nvidia驱动、cuda安装及卸载"></a><a href="https://blog.csdn.net/u013187057/article/details/81475806" target="_blank" rel="noopener">cuda、cudnn、驱动版本查看及nvidia驱动、cuda安装及卸载</a></h3><h3 id="ubuntu下卸载cuda8-0，和安装cuda9-0，cudnn7-0-tensorflow-gpu-1-8"><a href="#ubuntu下卸载cuda8-0，和安装cuda9-0，cudnn7-0-tensorflow-gpu-1-8" class="headerlink" title="ubuntu下卸载cuda8.0，和安装cuda9.0，cudnn7.0,tensorflow-gpu=1.8"></a><a href="https://blog.csdn.net/pursuit_zhangyu/article/details/80232550" target="_blank" rel="noopener">ubuntu下卸载cuda8.0，和安装cuda9.0，cudnn7.0,tensorflow-gpu=1.8</a></h3>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;〇、TensorFlow-与-cuda-的对应版本&quot;&gt;&lt;a href=&quot;#〇、TensorFlow-与-cuda-的对应版本&quot; class=&quot;headerlink&quot; title=&quot;〇、TensorFlow 与 cuda 的对应版本&quot;&gt;&lt;/a&gt;〇、TensorFlo
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="深度学习" scheme="http://www.zhuzongkui.top/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>评价准则</title>
    <link href="http://www.zhuzongkui.top/2018/10/07/evaluation/"/>
    <id>http://www.zhuzongkui.top/2018/10/07/evaluation/</id>
    <published>2018-10-07T03:35:50.000Z</published>
    <updated>2019-08-04T08:45:31.319Z</updated>
    
    <content type="html"><![CDATA[<ul><li><a href="http://www.cnblogs.com/robert-dlut/p/5276927.html" target="_blank" rel="noopener">谈谈评价指标中的宏平均和微平均</a></li><li><a href="https://blog.csdn.net/sinat_26917383/article/details/51114244" target="_blank" rel="noopener">分类器的性能表现评价（混淆矩阵，准确率，召回率，F1,mAP、ROC曲线）</a></li><li><a href="https://blog.csdn.net/sinat_26917383/article/details/75199996?locationNum=3&amp;fps=1" target="_blank" rel="noopener">python + sklearn ︱分类效果评估——acc、recall、F1、ROC、回归、距离</a></li><li><a href="https://www.cnblogs.com/sddai/p/5696870.html" target="_blank" rel="noopener">准确率(Accuracy), 精确率(Precision), 召回率(Recall)和F1-Measure</a></li></ul><hr><p>对于二分类问题，可将样例根据其真实类别和分类器预测类别划分为：</p><div class="table-container"><table><thead><tr><th>0</th><th style="text-align:center">1</th><th style="text-align:center">2</th><th style="text-align:center">真实类别</th><th style="text-align:center">预测类别</th></tr></thead><tbody><tr><td>真正例</td><td style="text-align:center">True Positive</td><td style="text-align:center">TP</td><td style="text-align:center">正例</td><td style="text-align:center">正例 </td></tr><tr><td>假正例</td><td style="text-align:center">False Positive</td><td style="text-align:center">FP</td><td style="text-align:center">负例</td><td style="text-align:center">正例 </td></tr><tr><td>假负例</td><td style="text-align:center">False Negative</td><td style="text-align:center">FN</td><td style="text-align:center">正例</td><td style="text-align:center">负例 </td></tr><tr><td>真负例</td><td style="text-align:center">True Negative</td><td style="text-align:center">TN</td><td style="text-align:center">负例</td><td style="text-align:center">负例 </td></tr></tbody></table></div><p>然后可以构建混淆矩阵（Confusion Matrix）如下表所示：</p><div class="table-container"><table><thead><tr><th>-</th><th style="text-align:center">预测 正例</th><th style="text-align:center">预测 负例 </th></tr></thead><tbody><tr><td><strong>真实 正例</strong></td><td style="text-align:center">TP</td><td style="text-align:center">FN </td></tr><tr><td><strong>真实 负例</strong></td><td style="text-align:center">FP</td><td style="text-align:center">TN</td></tr></tbody></table></div><hr><script type="math/tex; mode=display">\text{测试集：} X_{test} = \{(x_i, y_i) | i = 1, 2, ..., N \}</script><script type="math/tex; mode=display">N \text{：表示测试集中的样本个数}</script><script type="math/tex; mode=display">x_i \text{：表示测试集中的数据样本}</script><script type="math/tex; mode=display">y_i \text{：表示数据样本的类别号}</script><script type="math/tex; mode=display">\text{假设要研究的分类问题含有 m 个类别，则} y_i \in \{c_1, c_2, ..., c_m \}</script><script type="math/tex; mode=display">\text{在分类问题中对于测试集的第j个类别，假设被正确分类的样本数量为} TP_j</script><script type="math/tex; mode=display">\text{被错误分类的样本数量为} FN_j</script><script type="math/tex; mode=display">\text{其它类别被错误分类为该类的样本数量为} FP_j</script><hr><h2 id="精确度"><a href="#精确度" class="headerlink" title="精确度"></a>精确度</h2><script type="math/tex; mode=display">Accuracy = \frac {\sum_{j=1}^mTP_j} {N} = \frac {TP+TN} {N}</script><script type="math/tex; mode=display">= \frac { \text{分类正确的样本个数} } { \text{分类的所有样本个数} }</script><h2 id="查全率-召回率-R"><a href="#查全率-召回率-R" class="headerlink" title="查全率/召回率 R"></a>查全率/召回率 R</h2><ul><li>第j个类别的查全率表示在本类样本中，被正确分类的样本所占的比例，它表示这个类别的分类精度</li></ul><script type="math/tex; mode=display">Recall_j = \frac {TP_j} {TP_j + FN_j} , 1 \leq j \leq m</script><h2 id="查准率-准确率-P"><a href="#查准率-准确率-P" class="headerlink" title="查准率/准确率 P"></a>查准率/准确率 P</h2><ul><li>第j个类别的查准率表示被分类为该类的样本中，真正属于该类的样本所占的比例，它表示这个类别的分类纯度</li></ul><script type="math/tex; mode=display">Precision_j = \frac {TP_j} {TP_j + FP_j} , 1 \leq j \leq m</script><h2 id="F1-标准"><a href="#F1-标准" class="headerlink" title="F1 标准"></a>F1 标准</h2><ul><li>F1 值比较合理地评价分类器对每一类样本的分类性能。</li></ul><script type="math/tex; mode=display">F_\beta = \frac {(1 + \beta^2) * P * R} {(\beta^2 * P) + R}</script><script type="math/tex; mode=display">F1 = \frac {2 * R_j * P_j} {R_j + P_j} , 1 \leq j \leq m, \beta = 1</script><script type="math/tex; mode=display">= \frac {2} {1/P + 1/R}</script><hr><h2 id="宏平均-Macro-averaging"><a href="#宏平均-Macro-averaging" class="headerlink" title="宏平均 Macro-averaging"></a>宏平均 Macro-averaging</h2><ul><li>先对每一个类统计指标值，然后在对所有类<strong>求算术平均值</strong></li></ul><script type="math/tex; mode=display">Macro\_P = \frac{1}{n}\sum_{i=1}^mP_i</script><script type="math/tex; mode=display">Macro\_R = \frac{1}{n}\sum_{i=1}^mR_i</script><script type="math/tex; mode=display">Macro\_F = \frac{1}{n}\sum_{i=1}^mF_i</script><script type="math/tex; mode=display">Macro\_F = \frac {2 * Macro\_P * Macro\_R} {Macro\_P + Macro\_R}</script><h2 id="微平均-Micro-averaging"><a href="#微平均-Micro-averaging" class="headerlink" title="微平均 Micro-averaging"></a>微平均 Micro-averaging</h2><ul><li>对数据集中的每一个实例不分类别进行统计建立全局混淆矩阵，然后计算相应指标</li></ul><script type="math/tex; mode=display">Micro\_P = \frac {\sum_{i=1}^mTP_i} {\sum_{i=1}^mTP_i + \sum_{i=1}^mFP_i}</script><script type="math/tex; mode=display">= \frac {\sum_{i=1}^mTP_i} {N}</script><script type="math/tex; mode=display">Micro\_R = \frac {\sum_{i=1}^mTP_i} {\sum_{i=1}^mTP_i + \sum_{i=1}^mFN_i}</script><script type="math/tex; mode=display">= \frac {\sum_{i=1}^mTP_i} {N}</script><script type="math/tex; mode=display">Micro\_F = \frac {2 * Micro\_P * Micro\_R} {Micro\_P + Micro\_R}</script><script type="math/tex; mode=display">\text{如果对所有类别求微平均，那么上面三个值是相等的，且 = accuracy。}</script><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.cnblogs.com/robert-dlut/p/5276927.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;谈谈评价指标中的宏平均和微平均&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;ht
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="统计学习" scheme="http://www.zhuzongkui.top/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>特征选择方法</title>
    <link href="http://www.zhuzongkui.top/2018/10/06/feature_select/"/>
    <id>http://www.zhuzongkui.top/2018/10/06/feature_select/</id>
    <published>2018-10-06T10:24:38.000Z</published>
    <updated>2019-08-04T08:45:31.320Z</updated>
    
    <content type="html"><![CDATA[<ul><li>CHI、IG： <a href="http://songlj.iteye.com/blog/2241763" target="_blank" rel="noopener">http://songlj.iteye.com/blog/2241763</a></li><li>IG、CHI、TC、TS、IIG <a href="https://blog.csdn.net/Fighting_No1/article/details/51003386" target="_blank" rel="noopener">文本挖掘（四）——特征选择</a> </li><li><a href="https://blog.csdn.net/qq_16912257/article/details/52994788" target="_blank" rel="noopener">From My Github - 文本分类</a></li></ul><h3 id="表1：词频统计（文档数量）"><a href="#表1：词频统计（文档数量）" class="headerlink" title="表1：词频统计（文档数量）"></a>表1：词频统计（文档数量）</h3><p>其中，文档总数：N = A+B+C+D</p><div class="table-container"><table><thead><tr><th>-</th><th style="text-align:center">包含词条 t</th><th style="text-align:center">不包含词条 t</th></tr></thead><tbody><tr><td><strong>属于类别 c</strong></td><td style="text-align:center">A</td><td style="text-align:center">C</td></tr><tr><td><strong>不属于类别 c</strong></td><td style="text-align:center">B</td><td style="text-align:center">D </td></tr></tbody></table></div><hr><h2 id="1、文档频率-DF-（document-frequency）"><a href="#1、文档频率-DF-（document-frequency）" class="headerlink" title="1、文档频率 DF （document frequency）"></a>1、文档频率 DF （document frequency）</h2><ul><li>文档频率指训练集中包含该特征词条的文本总数</li></ul><script type="math/tex; mode=display">DF = A + B</script><p><code>选择 DF &gt; 某个阈值的特征词条</code></p><h2 id="2、信息增益-IG-（information-gain）"><a href="#2、信息增益-IG-（information-gain）" class="headerlink" title="2、信息增益 IG （information gain）"></a>2、信息增益 IG （information gain）</h2><ul><li>通过特征词在文本中出现和不出现前后的信息量之差来推断该特征词所带的信息量</li></ul><script type="math/tex; mode=display">IG(t) = H(c) - H(c|t)</script><script type="math/tex; mode=display">H(c) = - \sum_{i=1}^mP(c_i)log P(c_i)</script><script type="math/tex; mode=display">H(c|t) = - P(t) \sum_{i=1}^m P(c_i|t) log P(c_i|t) - P(\bar{t}) \sum_{i=1}^m P(c_i|\bar{t}) log P(c_i|\bar{t})</script><script type="math/tex; mode=display">P(t)=\frac {A+B}{N} \text{：表示样本集中包含词 t 的文本的概率}</script><script type="math/tex; mode=display">P(c_i)=\frac {A+C}{N} \text{：表示类文本在样本集中出现的概率}</script><script type="math/tex; mode=display">P(c_i|t)=\frac {A}{A+B} \text{：表示文本包含词 t 时属于 c 的条件概率}</script><h2 id="3、互信息-MI-（mutual-information）"><a href="#3、互信息-MI-（mutual-information）" class="headerlink" title="3、互信息 MI （mutual information）"></a>3、互信息 MI （mutual information）</h2><ul><li>互信息衡量了特征词条和类别之间的相关性<script type="math/tex; mode=display">MI(t,c) = log \frac {P(t,c)} {P(t)*P(c)} = log \frac {\frac{A}{N}} {\frac{A+B}{N}*\frac{A+C}{N}}</script><script type="math/tex; mode=display">= log \frac {A*N} {(A+C)*(A+B)} = log \frac { \frac{A}{A+C} } { \frac{A+B}{N} }</script><script type="math/tex; mode=display">= log \frac{A}{A+C} - log \frac{A+B}{N} = log P(t|c) - log P(t)</script><script type="math/tex; mode=display">MI_{avg}(t) = \sum_{i=1}^m P(c_i) MI(t,c_i)</script><script type="math/tex; mode=display">MI_{max}(t) = \max_{i=1}^m \{ MI(t,c_i) \}</script></li></ul><p>MI(t,c) = 0，当 t 和 c 相互独立时<br>弱点：得分被词条的边缘概率强烈的影响；（条件概率相等时，低频词比高频词有更高的分数）</p><h2 id="4、卡方统计-CHI（Chi-Square-Statistic）"><a href="#4、卡方统计-CHI（Chi-Square-Statistic）" class="headerlink" title="4、卡方统计 CHI（Chi-Square Statistic）"></a>4、卡方统计 CHI（Chi-Square Statistic）</h2><ul><li>卡方统计量也用于表征两个变量的相关性，与互信息相比，它同时考虑了特征在某类文本中出现和不出现时的情况</li><li>度量了 t 和 c 之间的独立性<script type="math/tex; mode=display">CHI(t,c) = \frac {N * (AD-BC)^2} {(A+C)*(B+D)*(A+B)*(C+D)}</script><script type="math/tex; mode=display">CHI_{avg}(t) = \sum_{i=1}^m P(c_i) CHI(t,c_i)</script><script type="math/tex; mode=display">CHI_{max}(t) = \max_{i=1}^m \{ CHI(t,c_i) \}</script></li><li>卡方统计是一个规范值，因此卡方统计值对于相同的类别可以跨词进行比较</li><li>如果列联表中的任何单元被轻微填充，这种归一化就会失效（低频词的例子）</li><li>因此，卡方统计对于低频词是不可靠的。</li></ul><h2 id="5、词条强度-单词权-TS-（term-strength）"><a href="#5、词条强度-单词权-TS-（term-strength）" class="headerlink" title="5、词条强度/单词权 TS （term strength）"></a>5、词条强度/单词权 TS （term strength）</h2><h3 id="法1：博客"><a href="#法1：博客" class="headerlink" title="法1：博客"></a>法1：<a href="https://blog.csdn.net/Fighting_No1/article/details/51003386" target="_blank" rel="noopener">博客</a></h3><ul><li>TS 计算的是一个词出现的条件概率，即该词在一对相关文本中的某一个文本中出现的条件下，在另一个文本中出现的概率<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">（1）计算文本数据集中每一对文本的相似度；</span><br><span class="line">（2）选择出所有相似度超过阈值的文本对；</span><br><span class="line">（3）对所有的单词，根据下式计算它的单词权。</span><br></pre></td></tr></table></figure></li></ul><script type="math/tex; mode=display">TS(t) = \frac {\text{均包含词t的相关文本对数}} {\text{文本集中的相关文本对总数}}</script><p>若有一个文本集，其中有N篇文本，M对相关文本有序对，有K对同时包含词t的相关文本有序对，则</p><script type="math/tex; mode=display">TS(t)=P(t|M) = \frac{K}{M} = \frac{\sum_{i=1}^m c_i\text{类包含词t相关文本对数}} {\sum_{i=1}^m c_i\text{类相关文本对数}}</script><script type="math/tex; mode=display">\approx \sum_{i=1}^m c_i\text{类包含词t相关文本对数}</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">即TS(t)表示在文本集的所有相关文本有序对的集合中，同时包含词t的相关文本有序对的比例。</span><br><span class="line">若TS(t)值越大，说明词t在相关文本集中出现得越多，即越重要。</span><br><span class="line">缺点：要计算文本间的相似度，所以复杂度较高；阈值不易确定。</span><br></pre></td></tr></table></figure><hr><h3 id="法2：（Yang-Yiming-论文里）文本聚类中的特征选择方法"><a href="#法2：（Yang-Yiming-论文里）文本聚类中的特征选择方法" class="headerlink" title="法2：（Yang Yiming 论文里）文本聚类中的特征选择方法"></a>法2：（Yang Yiming 论文里）<a href="http://www.docin.com/p-761617862.html" target="_blank" rel="noopener">文本聚类中的特征选择方法</a></h3><ul><li>这个方法基于词条出现在密切相关的文档中的频率来评估词条的重要性</li><li>使用一组训练文档来派生出文档对，其相似度（余弦值）高于某个阈值</li><li>x 和 y 是一对相似文档</li></ul><script type="math/tex; mode=display">TS(t) = P(t \in y | t \in x)</script><ul><li>基于文档聚类，假设有许多共享词的文档是相似的，在相关文档的重叠区域内的词条的信息量相对较大</li><li>这个方法不是基于特定任务的；不使用与词条类别相关的信息。</li></ul><hr><h3 id="法3：PPT-1-18页"><a href="#法3：PPT-1-18页" class="headerlink" title="法3：PPT-1 18页"></a>法3：<a href="https://wenku.baidu.com/view/d43cf16fb7360b4c2f3f643c.html" target="_blank" rel="noopener">PPT-1 18页</a></h3><ul><li><a href="https://wenku.baidu.com/view/2938f07f24c52cc58bd63186bceb19e8b8f6ec0d.html?re=view" target="_blank" rel="noopener">PPT-2 18页</a></li></ul><p>词强度（term strength）</p><script type="math/tex; mode=display">\text{已知一个词（特征）在某文档（实例）中出现，}</script><script type="math/tex; mode=display">\text{该词在同类（目标函数值相同）文档中出现的概率为词强度。}</script><script type="math/tex; mode=display">s(t) = P(t \in d_{Y=y}^i | t \in d_{Y=y}^j)</script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;CHI、IG： &lt;a href=&quot;http://songlj.iteye.com/blog/2241763&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://songlj.iteye.com/blog/2241763&lt;/a&gt;&lt;/li&gt;
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="统计学习" scheme="http://www.zhuzongkui.top/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>StandfordNLP NLTK 中文工具配置教程</title>
    <link href="http://www.zhuzongkui.top/2018/09/10/StandfordNLP%20NLTK/"/>
    <id>http://www.zhuzongkui.top/2018/09/10/StandfordNLP NLTK/</id>
    <published>2018-09-10T07:13:05.000Z</published>
    <updated>2019-08-04T08:45:31.315Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python3-NLTK-StandfordNLP-中文工具包配置教程"><a href="#Python3-NLTK-StandfordNLP-中文工具包配置教程" class="headerlink" title="Python3 NLTK StandfordNLP 中文工具包配置教程"></a>Python3 NLTK StandfordNLP 中文工具包配置教程</h1><ul><li><a href="https://www.cnblogs.com/baiboy/p/nltk1.html" target="_blank" rel="noopener">配置教程-1</a></li><li><a href="https://www.jianshu.com/p/4b3c7e7578e6" target="_blank" rel="noopener">配置教程-2</a></li></ul><h3 id="1-必要的安装包"><a href="#1-必要的安装包" class="headerlink" title="1. 必要的安装包"></a>1. 必要的安装包</h3><ul><li>Python3  <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">Anaconda3</a></li><li>NLTK <a href="https://www.anaconda.com/download/" target="_blank" rel="noopener">Anaconda3</a></li><li>jdk_1.8 <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Java SE Development Kit 8 Downloads</a></li><li>StanfordNLP <a href="https://nlp.stanford.edu/software/" target="_blank" rel="noopener">NLTK工具包</a></li><li>StanfordNLP 中文处理工具包 <a href="https://pan.baidu.com/s/1d5qTgpZgrgaA2LduSP6enw" target="_blank" rel="noopener">百度云链接</a> 密码：o1l3 【本人打包好】</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 中文处理工具包 stanford-jar.zip 文件内容: `ls`</span></span><br><span class="line">chinese.misc.distsim.crf.ser.gz  stanford-ner-3.9.1.jar</span><br><span class="line">chinese-distsim.tagger           stanford-parser.jar</span><br><span class="line">chinesePCFG.ser.gz               stanford-parser-3.9.1-models.jar</span><br><span class="line">data/                            stanford-postagger-3.9.1.jar</span><br><span class="line">slf4j-api-1.7.25.jar             stanford-segmenter-3.9.1.jar</span><br></pre></td></tr></table></figure><h3 id="2-调用代码"><a href="#2-调用代码" class="headerlink" title="2. 调用代码"></a>2. 调用代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"></span><br><span class="line"><span class="comment">## java 环境</span></span><br><span class="line">java_path = <span class="string">"D:\Program Files\Java\jdk1.8.0_162\\bin\java.exe"</span>  <span class="comment"># java安装地址</span></span><br><span class="line">os.environ[<span class="string">'JAVAHOME'</span>] = java_path</span><br><span class="line">base_dir = <span class="string">'D:\data\stanfordnlp\stanford-jar'</span>  <span class="comment"># StanfordNLP 中文处理工具包的路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 1. 分词</span></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br><span class="line"><span class="keyword">from</span> nltk.tokenize.stanford_segmenter <span class="keyword">import</span> StanfordSegmenter</span><br><span class="line">segmenter = StanfordSegmenter(</span><br><span class="line">    path_to_jar=os.path.join(base_dir, <span class="string">'stanford-segmenter-3.9.1.jar'</span>),</span><br><span class="line">    path_to_slf4j=os.path.join(base_dir, <span class="string">'slf4j-api-1.7.25.jar'</span>),</span><br><span class="line">    path_to_sihan_corpora_dict=os.path.join(base_dir, <span class="string">'data'</span>),</span><br><span class="line">    path_to_model=os.path.join(base_dir, <span class="string">'data/pku.gz'</span>),</span><br><span class="line">    path_to_dict=os.path.join(base_dir, <span class="string">'data/dict-chris6.ser.gz'</span>)</span><br><span class="line">)</span><br><span class="line">sent = <span class="string">'这是斯坦福中文分词器测试，南京市长江大桥。我在博客园开了一个博客，我的博客名叫伏草惟存，写了一些自然语言处理的文章。'</span></span><br><span class="line">print(segmenter.segment(sent))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 2. 命名实体识别NER</span></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> StanfordNERTagger</span><br><span class="line">chi_tagger = StanfordNERTagger(</span><br><span class="line">    model_filename=os.path.join(base_dir, <span class="string">'chinese.misc.distsim.crf.ser.gz'</span>),</span><br><span class="line">    path_to_jar=os.path.join(base_dir, <span class="string">'stanford-ner-3.9.1.jar'</span>)</span><br><span class="line">    )</span><br><span class="line">result = <span class="string">'四川省 成都 信息 工程 大学 我 在 博客 园 开 了 一个 博客 ， 我 的 博客 名叫 伏 草 惟 存 ， 写 了 一些 自然语言 处理 的 文章 。\r\n'</span></span><br><span class="line"><span class="keyword">for</span> word, tag <span class="keyword">in</span>  chi_tagger.tag(result.split()):</span><br><span class="line">    print(word,tag)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 3. 词性标注</span></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br><span class="line"><span class="keyword">from</span> nltk.tag <span class="keyword">import</span> StanfordPOSTagger</span><br><span class="line">chi_tagger = StanfordPOSTagger(</span><br><span class="line">    model_filename=os.path.join(base_dir, <span class="string">'chinese-distsim.tagger'</span>),</span><br><span class="line">    path_to_jar=os.path.join(base_dir, <span class="string">'stanford-postagger-3.9.1.jar'</span>)</span><br><span class="line">    )</span><br><span class="line">result = <span class="string">'四川省 成都 信息 工程 大学 我 在 博客 园 开 了 一个 博客 ， 我 的 博客 名叫 伏 草 惟 存 ， 写 了 一些 自然语言 处理 的 文章 。\r\n'</span></span><br><span class="line">print(chi_tagger.tag(result.split()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 4. 句法分析</span></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br><span class="line"><span class="keyword">from</span> nltk.parse.stanford <span class="keyword">import</span> StanfordParser</span><br><span class="line">chi_parser = StanfordParser(</span><br><span class="line">    os.path.join(base_dir, <span class="string">'stanford-parser.jar'</span>),</span><br><span class="line">    os.path.join(base_dir, <span class="string">'stanford-parser-3.9.1-models.jar'</span>),</span><br><span class="line">    os.path.join(base_dir, <span class="string">'chinesePCFG.ser.gz'</span>)</span><br><span class="line">    )</span><br><span class="line">sent = <span class="string">u'北海 已 成为 中国 对外开放 中 升起 的 一 颗 明星'</span></span><br><span class="line">print(list(chi_parser.parse(sent.split())))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 5. 依存句法分析</span></span><br><span class="line"><span class="comment">#########################################################################################</span></span><br><span class="line"><span class="keyword">from</span> nltk.parse.stanford <span class="keyword">import</span> StanfordDependencyParser</span><br><span class="line">chi_parser = StanfordDependencyParser(</span><br><span class="line">    os.path.join(base_dir, <span class="string">'stanford-parser.jar'</span>),</span><br><span class="line">    os.path.join(base_dir, <span class="string">'stanford-parser-3.9.1-models.jar'</span>),</span><br><span class="line">    os.path.join(base_dir, <span class="string">'chinesePCFG.ser.gz'</span>)</span><br><span class="line">    )</span><br><span class="line">res = list(chi_parser.parse(<span class="string">'四川 已 成为 中国 西部 对外开放 中 升起 的 一 颗 明星'</span>.split()))</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> res[<span class="number">0</span>].triples():</span><br><span class="line">    print(row)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Python3-NLTK-StandfordNLP-中文工具包配置教程&quot;&gt;&lt;a href=&quot;#Python3-NLTK-StandfordNLP-中文工具包配置教程&quot; class=&quot;headerlink&quot; title=&quot;Python3 NLTK Standford
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="NLP" scheme="http://www.zhuzongkui.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>简单使用 Git</title>
    <link href="http://www.zhuzongkui.top/2018/09/10/git/"/>
    <id>http://www.zhuzongkui.top/2018/09/10/git/</id>
    <published>2018-09-10T07:12:16.000Z</published>
    <updated>2019-09-03T01:15:17.474Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><ul><li>Git简明指南：（可能需要翻墙）<a href="http://rogerdudler.github.io/git-guide/index.zh.html" target="_blank" rel="noopener">git - 简明指南</a></li><li>码云（Gitee.com）<a href="http://git.mydoc.io/" target="_blank" rel="noopener">帮助文档</a></li><li>官网：<a href="https://git-scm.com/" target="_blank" rel="noopener">https://git-scm.com/</a></li><li>入门教程：<a href="https://git-scm.com/book/zh/v2" target="_blank" rel="noopener">https://git-scm.com/book/zh/v2</a></li><li><a href="https://www.liaoxuefeng.com/wiki/896043488029600" target="_blank" rel="noopener">廖雪峰Git教程</a></li><li>菜鸟教程：<a href="https://www.runoob.com/git/git-tutorial.html" target="_blank" rel="noopener">https://www.runoob.com/git/git-tutorial.html</a></li><li>易百教程：<a href="https://www.yiibai.com/git" target="_blank" rel="noopener">https://www.yiibai.com/git</a></li><li>远程仓库：<a href="github.com">github</a>, <a href="gitlab.com">gitlab</a>, <a href="gitee.com">gitee</a></li></ul><h1 id="一、入门"><a href="#一、入门" class="headerlink" title="一、入门"></a>一、入门</h1><h2 id="1、简单配置"><a href="#1、简单配置" class="headerlink" title="1、简单配置"></a>1、简单配置</h2><p>1、初始配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ git config --global user.name &quot;你的用户名&quot;</span><br><span class="line">$ git config --global user.email &quot;你的邮箱地址&quot;</span><br></pre></td></tr></table></figure><p>2、查看配置信息：<code>git config --list</code></p><p>3、添加：<code>git add .</code>，删除：<code>git rm &lt;filename&gt;</code></p><p>4、删除和提交：<code>git commit -m &quot;这一步操作的名字&quot;</code></p><p>5、推送到远端：<code>git push origin master</code></p><p>6、远程服务器：<code>git remote add origin &lt;仓库&gt;</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git remote add &lt;name&gt; &lt;url&gt;   # 添加一个仓库</span><br><span class="line">$ git remote remove &lt;name&gt;  # 删除一个远程仓库</span><br><span class="line">$ git remote -v                     # 查看当前仓库对应的远程仓库地址</span><br></pre></td></tr></table></figure><p>7、查看本地仓库的历史记录log：<code>git log --author=你的用户名字</code></p><p>8、可以查看改动记录：<code>git status</code></p><h2 id="2、项目在本地，推送到远程"><a href="#2、项目在本地，推送到远程" class="headerlink" title="2、项目在本地，推送到远程"></a>2、项目在本地，推送到远程</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;项目的文件夹&gt;                  <span class="comment">#【工作区：working dir】</span></span><br><span class="line">git init</span><br><span class="line">&lt;放项目文件等一系列操作&gt;</span><br><span class="line">git add .                         <span class="comment">#【暂存区：stage 或 index】</span></span><br><span class="line">git commit -m <span class="string">"first commit"</span>      <span class="comment">#【仓库区：HEAD】</span></span><br><span class="line"></span><br><span class="line">git remote add origin &lt;server&gt;</span><br><span class="line">git push -u origin master <span class="comment"># 使用-u选项指定一个默认主机</span></span><br><span class="line"><span class="comment"># 加了参数-u后，以后即可直接用git push代替git push origin master</span></span><br><span class="line">git push origin <span class="comment"># 将当前分支推送到origin主机的对应分支</span></span><br></pre></td></tr></table></figure><h2 id="3、项目在远程，下载并推送"><a href="#3、项目在远程，下载并推送" class="headerlink" title="3、项目在远程，下载并推送"></a>3、项目在远程，下载并推送</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> &lt;server&gt; <span class="comment"># 项目地址 https://github.com/xxxx.git</span></span><br><span class="line">git submodule update --init --recursive <span class="comment"># 项目中带有submodule</span></span><br><span class="line"><span class="built_in">cd</span> &lt;项目的文件夹&gt;</span><br><span class="line"><span class="comment"># git pull origin master  # 与远程同步，更新你的本地仓库至最新改动</span></span><br><span class="line">&lt;这里需要修改/添加文件，否则与原文件相比就没有变动&gt;</span><br><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">"第一次提交"</span></span><br><span class="line">git push origin master</span><br><span class="line"><span class="comment"># 然后如果需要账号密码的话就输入账号密码，这样就完成了一次提交</span></span><br></pre></td></tr></table></figure><h2 id="4、注意（本地和远程冲突）"><a href="#4、注意（本地和远程冲突）" class="headerlink" title="4、注意（本地和远程冲突）"></a>4、注意（本地和远程冲突）</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 按照本文档新建的项目时，在码云平台仓库上已经存在 readme 文件，故在提交时可能会存在冲突，这时您需要选择的是保留线上的文件或者舍弃线上的文件。</span></span><br><span class="line"><span class="comment"># 如果您舍弃线上的文件，则在推送时选择强制推送，强制推送需要执行下面的命令：</span></span><br><span class="line">git push origin master -f</span><br><span class="line"><span class="comment"># 如果您选择保留线上的 readme 文件,则需要先执行：</span></span><br><span class="line">git pull origin master</span><br><span class="line"><span class="comment"># 然后才可以推送</span></span><br></pre></td></tr></table></figure><h2 id="5、配置ssh-key"><a href="#5、配置ssh-key" class="headerlink" title="5、配置ssh key"></a>5、配置ssh key</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C &apos;xxx@xxx.com&apos;  # 然后一路回车(-C 参数是你的邮箱地址)</span><br><span class="line">打开文件 C:\Users\Administrator\.ssh\id_rsa.pub，复制内容</span><br><span class="line">打开 github --&gt; Settings --&gt; SSH and GPG keys --&gt; New SSH key</span><br><span class="line">把上一步中复制的内容粘贴到Key所对应的文本框，在Title对应的文本框中给这个sshkey设置一个名字，点击Add key按钮</span><br><span class="line">ssh -T git@github.com  # 验证一下</span><br></pre></td></tr></table></figure><h1 id="二、分支操作"><a href="#二、分支操作" class="headerlink" title="二、分支操作"></a>二、分支操作</h1><h2 id="相关操作"><a href="#相关操作" class="headerlink" title="相关操作"></a>相关操作</h2><p>1、创建分支：<code>git branch feature_x</code></p><p>2、切换分支：<code>git checkout feature_x</code></p><p>3、创建分支并切换过去：<code>git checkout -b feature_x</code></p><p>4、删除分支：<code>git branch -d feature_x</code></p><p>5、推送分支：<code>git push origin feature_x</code></p><p>6、列出分支：<code>git branch</code></p><p>7、重命名分支：<code>git branch -m old_branch new_branch</code></p><h1 id="三、标签"><a href="#三、标签" class="headerlink" title="三、标签"></a>三、标签</h1><p>1、添加标签：<code>git tag -a &lt;tagname&gt; -m &lt;操作名&gt;</code></p><h1 id="四、更新"><a href="#四、更新" class="headerlink" title="四、更新"></a>四、更新</h1><p>1、同步远程和本地合并：<code>git pull</code>  == <code>fetch</code> <code>merge</code></p><p>2、放弃本地，只要远程：<code>git fetch origin</code></p><h1 id="五、忽略"><a href="#五、忽略" class="headerlink" title="五、忽略"></a>五、忽略</h1><ul><li>有些时候，你必须把某些文件放到Git工作目录中，但又不能提交它们，比如保存了数据库密码的配置文件等。</li><li>在Git工作区的根目录下创建一个特殊的.gitignore文件，然后把要忽略的文件名填进去，Git就会自动忽略这些文件。</li></ul><h2 id="gitignore-文件"><a href="#gitignore-文件" class="headerlink" title=".gitignore 文件"></a>.gitignore 文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">*.log</span><br><span class="line">temp</span><br><span class="line">/vendor</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Git简明指南：（可能需要翻墙）&lt;a href=&quot;http://rogerdudler.github.io/git-guide/index.zh.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;git - 简明
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Git" scheme="http://www.zhuzongkui.top/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>问题对语义相似度计算-参赛总结</title>
    <link href="http://www.zhuzongkui.top/2018/08/10/competition-summary/"/>
    <id>http://www.zhuzongkui.top/2018/08/10/competition-summary/</id>
    <published>2018-08-10T00:55:07.000Z</published>
    <updated>2019-08-04T08:45:31.318Z</updated>
    
    <content type="html"><![CDATA[<ul><li>时间段：2018.06.10~2018.07.20</li></ul><h1 id="问题对语义相似度计算（从0到0-5-）"><a href="#问题对语义相似度计算（从0到0-5-）" class="headerlink" title="问题对语义相似度计算（从0到0.5+）"></a>问题对语义相似度计算（从0到0.5+）</h1><ul><li>短短一个多月的时间，我学到了很多很多东西，从一个呆头小白初长成人。</li><li>首先，必须感谢我的导师能给我这个机会从头到尾完整地参加这次比赛，至始至终地为我们出谋划策，和我们探讨问题并答疑解惑，而且提供了各种宝贵的学习资料和服务器资源。</li><li>另外，也要特别感谢我的师兄一路无微不至的提点和帮助，和我一起找方法、看论文、搭模型、改代码，其实我们是从同一个起跑线开始的，到最后被师兄甩了好几条街 T_T。</li><li>虽然，比赛期间遇到了很多挫折，刚开始我们真的是一头雾水、无从下手，面对参加同样比赛的其他优秀选手（“老油条”）心里还是蛮慌的，好在勤能补拙，有团队配合，能够齐心协力、互相帮助，最终比赛的结果还算令人满意。</li></ul><h3 id="一、相关比赛"><a href="#一、相关比赛" class="headerlink" title="一、相关比赛"></a>一、相关比赛</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">任务：语句匹配问题、语义等价判别、语义等价判定、等价；（语句的意图匹配）</span><br><span class="line">输入：一个语句对</span><br><span class="line">输出：一个数值（0-1之间），表明该语句对的相似程度</span><br></pre></td></tr></table></figure><ul><li>第三届魔镜杯大赛 <a href="https://ai.ppdai.com/mirror/goToMirrorDetail?mirrorId=1" target="_blank" rel="noopener">问题相似度算法设计</a></li><li>2018 全国知识图谱与语义计算大会 <a href="http://www.ccks2018.cn/?page_id=16" target="_blank" rel="noopener">任务三：微众银行智能客服问句匹配大赛</a><ul><li>比赛平台：<a href="https://biendata.com/competition/CCKS2018_3/" target="_blank" rel="noopener">CCKS 2018 微众银行智能客服问句匹配大赛</a></li></ul></li><li>ATEC蚂蚁开发者大赛 <a href="https://dc.cloud.alipay.com/index#/topic/intro?id=3" target="_blank" rel="noopener">金融大脑-金融智能NLP服务</a>  <a href="https://blog.csdn.net/u014732537/article/details/81038260" target="_blank" rel="noopener">博客分享</a></li><li>… …</li></ul><h3 id="二、数据形式"><a href="#二、数据形式" class="headerlink" title="二、数据形式"></a>二、数据形式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">魔镜杯：脱敏数据，所有原始文本信息都被编码成单字ID序列和词语ID序列。</span><br><span class="line">label,q1,q2</span><br><span class="line">1,Q397345,Q538594</span><br><span class="line">0,Q193805,Q699273</span><br><span class="line">0,Q085471,Q676160</span><br><span class="line">... ...</span><br><span class="line"></span><br><span class="line">CCKS：中文的真实客服语料。</span><br><span class="line">用微信都6年，微信没有微粒贷功能4。  号码来微粒贷0</span><br><span class="line">微信消费算吗还有多少钱没还0</span><br><span class="line">交易密码忘记了找回密码绑定的手机卡也掉了怎么最近安全老是要改密码呢好麻烦0</span><br><span class="line">... ...</span><br><span class="line"></span><br><span class="line">蚂蚁：蚂蚁金服金融大脑的实际应用场景。</span><br><span class="line">1怎么更改花呗手机号码我的花呗是以前的手机号码，怎么更改成现在的支付宝的号码手机号1</span><br><span class="line">2也开不了花呗，就这样了？完事了真的嘛？就是花呗付款0</span><br><span class="line">3花呗冻结以后还能开通吗我的条件可以开通花呗借款吗0</span><br><span class="line">... ...</span><br></pre></td></tr></table></figure><h3 id="三、解决方案"><a href="#三、解决方案" class="headerlink" title="三、解决方案"></a>三、解决方案</h3><h4 id="（1）问题分析"><a href="#（1）问题分析" class="headerlink" title="（1）问题分析"></a>（1）问题分析</h4><ul><li>预测问题对的相似程度，即判别问题对是属于类别1还是类别0，很明显这是一个NLP领域的分类问题，然而区别于传统的文本分类问题：</li></ul><div class="table-container"><table><thead><tr><th>区别</th><th>传统文本分类</th><th>问题对相似度计算</th></tr></thead><tbody><tr><td>输入</td><td>只有一个输入</td><td>有两个输入</td></tr><tr><td>句子长度</td><td>文本较长</td><td>句子长短不一、且较简短</td></tr><tr><td>特征</td><td>文本特征</td><td>语义特征</td></tr><tr><td>。。。</td><td>。。。</td><td>。。。</td></tr></tbody></table></div><h4 id="（2）数据分析"><a href="#（2）数据分析" class="headerlink" title="（2）数据分析"></a>（2）数据分析</h4><ul><li>1、正负样本比例接近于 1：1；</li><li>2、相似的句子之间一般都会含有公共词/字符；也会出现包含很多公共词/字符，但句子主语不一样导致两个句子不相似的情况；</li><li>3、比赛的数据是没有经过预处理的（去停用词、繁体转简体、清洗）；另外数据中也存在很多脏数据（标注有误、错别字、漏字、简写），也很容易导致分词错误；</li><li>4、预训练的词向量数据（除非比赛方提供，否则还需要跟领域相关的语料来进行训练）；</li></ul><h4 id="（3）分类模型"><a href="#（3）分类模型" class="headerlink" title="（3）分类模型"></a>（3）分类模型</h4><p>其实我们之前是没有接触过这种类型的比赛的，也没有很多参赛的经验，而是刚刚从零学起，一步一步地摸索，沿着前人的脚步再延伸。</p><ul><li>1、比赛方（魔镜杯）Demo：两个句子拼成一个文本，空格连接，以 tfidf 为特征，做逻辑回归；（研究官方Demo时发现代码里有bug：最后提交的是预测为0的概率，实际应该是1）</li><li>2、借鉴官方Demo，两个句子拼接，使用传统CNN做文本分类，准确率 80% 左右；经测试q1和q2两个句子分开单独处理后再合并做分类效果是明显好于q1和q2先合并再处理后做分类的；</li></ul><div class="table-container"><table><thead><tr><th>q1、q2 分开单独处理</th><th>共享卷积层</th><th>不共享卷积层</th></tr></thead><tbody><tr><td>log_loss</td><td>0.258995</td><td>0.28949</td></tr></tbody></table></div><ul><li>3、微软发表的一篇论文[1]：DSSM模型（把条目映射成低维向量、计算查询和文档的cosine相似度，即一个查询语句对应多个文档，所以这个模型不太适用这个比赛）<ul><li><a href="https://blog.csdn.net/zkq_1986/article/details/79128844" target="_blank" rel="noopener">DSSM深度结构化语义模型原理</a></li><li><a href="http://ju.outofmemory.cn/entry/316660" target="_blank" rel="noopener">深度语义匹配模型-DSSM 及其变种</a></li><li><a href="https://cloud.tencent.com/developer/article/1005600" target="_blank" rel="noopener">深度学习解决 NLP 问题：语义相似度计算</a></li><li><a href="https://mp.weixin.qq.com/s/nbT4GSUbgh-5d1J79IqeDA?spm=a2c4e.11153940.blogcont174908.5.7f1e74e1yYbgV4" target="_blank" rel="noopener">PaperWeekly 第37期 | 论文盘点：检索式问答系统的语义匹配模型（神经网络篇）</a></li></ul></li><li>4、Quora <a href="https://engineering.quora.com/Semantic-Question-Matching-with-Deep-Learning" target="_blank" rel="noopener">Semantic Question Matching with Deep Learning</a> 三个LSTM模型，可以作为以下介绍的模型的baseline，进本是基于LSTM和Attention展开。</li><li>5、<a href="https://nlp.stanford.edu/projects/snli/" target="_blank" rel="noopener">The Stanford Natural Language Inference (SNLI) Corpus</a> 一大堆模型及特征提取方法，很多都是用了模型融合。</li><li>6、<a href="https://github.com/faneshion/MatchZoo" target="_blank" rel="noopener">MatchZoo</a> 12个模型，可能这个工具包是针对QuoraQP数据已经调好了参数，在移植到我们这个比赛的时候效果不是很佳，但可以借鉴。</li><li>7、相关博客（句子对匹配方法）<ul><li><a href="https://blog.csdn.net/malefactor/article/details/50669741" target="_blank" rel="noopener">使用深度双向LSTM模型构造社区问答系统</a> 重现后，效果不是很好</li><li><a href="https://blog.csdn.net/mpk_no1/article/details/72618683" target="_blank" rel="noopener">深度学习笔记——基于双向RNN（LSTM、GRU）和Attention Model的句子对匹配方法</a> 4个模型，其中 Soft Attention Model 实现后效果较好。</li><li><a href="https://blog.csdn.net/diye2008/article/details/53762124?ref=myread" target="_blank" rel="noopener">CNN在NLP领域的应用（2） 文本语义相似度计算</a> 类似方法2</li><li><a href="https://www.jianshu.com/p/a649b568e8fa" target="_blank" rel="noopener">LSTM 句子相似度分析</a> LSTM 简化版</li></ul></li><li>8、Siamese Network 孪生网络<ul><li><a href="https://www.jianshu.com/p/92d7f6eaacf5" target="_blank" rel="noopener">Siamese network 孪生神经网络—一个简单神奇的结构</a>     </li><li><a href="https://blog.csdn.net/thriving_fcl/article/details/73730552" target="_blank" rel="noopener">用于文本相似的Siamese Network</a></li><li><a href="https://blog.csdn.net/sxf1061926959/article/details/54836696" target="_blank" rel="noopener">Siamese Network理解（附代码）</a></li><li><a href="https://blog.csdn.net/sinat_24143931/article/details/78919432" target="_blank" rel="noopener">Siamese Network原理</a></li></ul></li><li>9、ESIM （这个模型是所有模型里面实现后效果最好的，但也有改动，对于脱敏数据是不能实现TreeLSTM的）<ul><li>源代码：<a href="https://github.com/coetaur0/ESIM" target="_blank" rel="noopener">ESIM_keras</a></li><li>Kaggle Competition: Quora Question Pairs Problem  <a href="https://github.com/yuhsinliu1993/Quora_QuestionPairs_DL" target="_blank" rel="noopener">a single model - ESIM</a></li></ul></li><li>10、论文[2]里的4个模型：SSE、PWIM、DecAtt、ESIM<ul><li><a href="https://github.com/lanwuwei/SPM_toolkit" target="_blank" rel="noopener">论文开源代码</a> </li></ul></li><li>11、论文[3]：BiMPM模型 <a href="https://github.com/zhiguowang/BiMPM" target="_blank" rel="noopener">github源码</a><br>论文[4]：DR-BiLSTM模型</li><li>12、gensim 相似度查询<ul><li><a href="https://blog.csdn.net/questionfish/article/details/46746947" target="_blank" rel="noopener">Gensim官方教程翻译（四）——相似度查询（Similarity Queries）</a> </li><li><a href="https://blog.csdn.net/qq_19707521/article/details/79352455" target="_blank" rel="noopener">gensim 相似度查询（Similarity Queries）(三)</a></li><li><a href="https://blog.csdn.net/jdbc/article/details/49924665" target="_blank" rel="noopener">nltk-比较中文文档相似度-完整实例</a></li><li><a href="https://my.oschina.net/kakablue/blog/314513" target="_blank" rel="noopener">nltk-比较中文文档相似度-完整实例</a></li></ul></li><li>13、传统模型工具：xgboost(xgb)、lightgbm(lgb)、随机森林random forest(rf)、极端随机树 Extremely randomized trees(ET或Extra-Trees)</li><li>14、<a href="http://note.youdao.com/noteshare?id=e380c70f7ecd137a12c0bf5949fc0d03&amp;sub=7D5CCB14202F41FA965F57D6AAF16B18" target="_blank" rel="noopener">前10选手用到的模型</a></li></ul><blockquote><p>最终单模型的最好效果：log_loss = 0.205189</p></blockquote><p>比赛期间，我实现或者在实现的基础上改进前前后后大概搭建了20多个模型，其实很多模型都还有很大的提升空间，局限于比赛的时间和自己的知识能力，而且在模型的细微之处、参数的初始化以及调参方面自己都没有什么经验，以致自己实现的模型的效果都没有师兄的好 (；へ：)。<br>虽然我们没能进入拍拍贷“魔镜杯”比赛的决赛，但在导师的帮助和特殊关系下，我们也有幸了参加了 top10 选手精彩的决赛答辩(2018-7-24 09:00)，真的受益匪浅。</p><h4 id="（4）模型调参"><a href="#（4）模型调参" class="headerlink" title="（4）模型调参"></a>（4）模型调参</h4><ul><li>1、拍拍贷一同比赛的某位优秀选手（初赛第16名, 复赛第12名）分享的博客 <a href="https://www.jianshu.com/p/827dd447daf9?utm_campaign=hugo&amp;utm_medium=reader_share&amp;utm_content=note&amp;utm_source=qq" target="_blank" rel="noopener">智能客服问题相似度算法设计——第三届魔镜杯大赛第12名解决方案</a><ul><li>队伍：moka_tree 团队</li><li><a href="https://github.com/LittletreeZou/Question-Pairs-Matching" target="_blank" rel="noopener">代码分享</a></li></ul></li><li><p>2、其实，很多参数我自己设置的都是默认参数，具体没有做很多的微调：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">embedding_dim = 300         # 词向量的维度</span><br><span class="line">seq_length = 25             # 文本的最大长度</span><br><span class="line">filter_sizes = [3]          # 卷积核尺寸列表</span><br><span class="line">num_classes = 2             # 类别数</span><br><span class="line">  </span><br><span class="line">is_pre_train = True         # 是否为训练好的词向量</span><br><span class="line">is_trainable = True         # 动态/静态词向量</span><br><span class="line"></span><br><span class="line">num_filters = 300           # 卷积核数目</span><br><span class="line">rnn_num_layers = 2          # LSTM 隐藏层的个数</span><br><span class="line">attention_size = 300        # Attention 层的大小</span><br><span class="line">rnn_hidden_size = 300       # LSTM 隐藏层的大小</span><br><span class="line">dropout_keep_prob = 0.5     # dropout 保留比例</span><br><span class="line">learning_rate = 1e-3        # 学习率（设置自动衰减）</span><br><span class="line">batch_size = 128            # 每批训练的大小</span><br></pre></td></tr></table></figure></li><li><p>3、参数初始化：跟上面博客里分享的一样，TensorFlow里面参数初始化不同，对结果的影响非常大，师兄推荐也是使用 Xavier 初始化；原本想用keras再实现一遍的，一方面不太熟悉，另一方面由于时间紧迫未能完成。</p></li><li>4、决赛答辩里，我们了解到很多选手并没有使用官方给定词级和字符级的词向量（不知道训练方法、参数、模型等），都自己训练了两种词向量（word2vec、glove）；另外也有用 w_vector * w_tfidf 作为 w 的词向量。</li><li>5、重点关注字向量：由于中文分词难度较大，特别是不同领域内的领域分词没有很好的解决方案（比赛数据为金融领域数据源），而且实验的效果也表明词级别是好于字级别的。</li><li>6、BatchNormalization + Spatial Dropout 1D</li></ul><h4 id="（5）特征工程"><a href="#（5）特征工程" class="headerlink" title="（5）特征工程"></a>（5）特征工程</h4><p>1、人工设计特征这部分是我们团队中来也公司的几个小伙伴做的， 他们参考并设计了很多有趣的特征。</p><ul><li>统计特征：句长、公共词、fuzzywuzzy、stat_feature、cosine 欧式 明氏 切氏等距离、多项式 拉普拉斯 sigmod等核函数、重叠词、重叠字等特征；<ul><li><a href="https://www.kaggle.com/act444/lb-0-158-xgb-handcrafted-leaky" target="_blank" rel="noopener">XGB_handcrafted_leaky</a></li></ul></li><li>主题特征：powerful words、tfidf matrix、PCA、NMF、NLP feature；<ul><li><a href="https://github.com/abhishekkrthakur/is_that_a_duplicate_quora_question" target="_blank" rel="noopener">is_that_a_duplicate_quora_question</a></li></ul></li><li>图特征 <ul><li><a href="https://github.com/HouJP/kaggle-quora-question-pairs/blob/master/bin/feature_engineering/graph.py" target="_blank" rel="noopener">kaggle-quora-question-pairs</a></li></ul></li></ul><p>2、其他选手</p><ul><li>计算QA pair的几种相似度：编辑距离、马氏距离、闵可夫斯基距离、WMD</li><li>使用 SVD、NMF对句中词向量降维</li><li>根据共现图，统计节点的degree，得到了两个比较强的特征：coo_q1_q2_degree_diff（问题1和问题2的degree的差异）、coo_max_degree（问题对最大的degree，进一步离散化做1-hot又得到3个特征）</li><li>问题对公共邻居的数量/比例</li><li>第一名：提取问题出入度、pagerank等特征；问题出现的次数以及频繁程度特征；将所有已知的问题构建同义问题集。问题集的构建不参与训练，只用于数据增强；</li></ul><p>3、数据增强</p><ul><li>第一名的方法  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">假设 Q1 在所有样本里出现2次，分别是</span><br><span class="line">1，Q1，Q2</span><br><span class="line">1，Q3，Q1</span><br><span class="line">模型无法正确学习Q1与Q2/Q3的相同，而是会认为只要input里有Q1即为正样本。</span><br><span class="line">需要通过数据处理引导模型进行“比较”，而不是“拟合”。</span><br><span class="line">解决方案：通过构建一部分补充集（负例），对冲所有不平衡的问题。</span><br></pre></td></tr></table></figure></li></ul><p>4、后处理</p><ul><li>传递关系<ul><li>相似：（AB=1，AC=1）—&gt; BC=1</li><li>不相似：（AB=1，AC=0）—&gt; BC=0</li></ul></li><li>第一名的方法：infer机制：除了判断test集的每个样本得分以外，还会通过已知同义问题集的其他样本比对进行加权；融合时轻微降低得分过高的模型权重，补偿正样本过多的影响；将已知确认的样本修正为0/1。</li></ul><p>比别人差的一个重要原因：传递关系没有考虑到闭包！我们大概推了1253条，然而别人正例推了12568个样本，负例推了5129个样本。  ╥﹏╥</p><h4 id="（6）模型融合"><a href="#（6）模型融合" class="headerlink" title="（6）模型融合"></a>（6）模型融合</h4><ul><li>1、多模型的融合最常用的一个方法就是<strong>求平均</strong>，我使用这个方法后 logloss 有很大的提升（加权平均的几个结果都是线上提交后 logloss 在 0.205189~0.209739 之间）。</li></ul><div class="table-container"><table><thead><tr><th>求平均的数量</th><th>2</th><th>4</th><th>7</th><th>8</th><th>9</th></tr></thead><tbody><tr><td>线上提交 logloss</td><td>0.187845</td><td>0.185329</td><td>0.182613</td><td>0.179808</td><td>0.179063</td></tr></tbody></table></div><ul><li>2、同一个模型提升效果的常用方法就是<strong>多折交叉验证求平均</strong>，由于我们组内 GPU 服务器有限，这个就由模型效果比较好的师兄来完成了，而且提升也是非常明显的。</li><li>3、另外，也用了堆叠和混合（stacking与blending）。<ul><li>每个模型 word level（官方词向量）</li><li>每个模型 word level（word2vec）</li><li>每个模型 word level（glove）</li><li>每个模型 char level（官方字向量）</li><li>每个模型 char level（word2vec）</li><li>每个模型 char level（glove）</li></ul></li><li>4、<a href="https://blog.csdn.net/a358463121/article/details/53054686" target="_blank" rel="noopener">kaggle比赛集成指南</a></li><li>5、模型微调（Finetune）<ul><li>第一名的方法：gensim训练词向量；模型使用non_trainable词向量进行训练；将除了embedding的layer全部freeze，用低学习率finetune词向量层。</li></ul></li></ul><div class="table-container"><table><thead><tr><th>小 trick</th><th>贡献度</th></tr></thead><tbody><tr><td>多模型的预测结果求平均</td><td>logloss 降低 2.6 个百分点</td></tr><tr><td>同一个模型10折交叉验证</td><td>logloss 降低 2 个 百分点</td></tr><tr><td>传递关系推导</td><td>logloss 降低 3.1 个千分点 </td></tr></tbody></table></div><h3 id="四、比赛总结"><a href="#四、比赛总结" class="headerlink" title="四、比赛总结"></a>四、比赛总结</h3><ul><li>1、比赛成绩（logloss / F1）</li></ul><div class="table-container"><table><thead><tr><th>拍拍贷</th><th>初赛成绩（359只队伍）</th><th>复赛成绩（95只队伍）</th></tr></thead><tbody><tr><td>我们</td><td>0.166100（第22名）</td><td>0.162495（第21名）</td></tr><tr><td>moka_tree</td><td>0.163249（第16名）</td><td>0.151729（第12名）</td></tr><tr><td>SKY</td><td>0.141329（第1名）</td><td>0.142658（第1名）</td></tr></tbody></table></div><div class="table-container"><table><thead><tr><th>CCKS</th><th>初赛成绩（138只队伍）</th><th>复赛成绩（50只队伍）</th></tr></thead><tbody><tr><td>我们</td><td>0.85142（第24名）</td><td>0.84586（第4名）</td></tr><tr><td>ThunderUp</td><td>0.86485（第1名）</td><td>0.85131（第1名）</td></tr></tbody></table></div><ul><li>2、经验体会<ul><li>刚开始，我们都是尝试各种模型，不知道哪一个好，在这个上面花了不少时间，其实从平时就应该开始积累，关注最新研究、最新模型，多看一下论坛、kaggle、quora、github、和NLP相关的公众号等。</li><li>一定要从数据本身上做探索，研究各种特征，因为到比赛后期模型基本都相似了，很难再有更大的提升；从决赛答辩来看，前10的选手在数据特征上都下了非常大的功夫，比如图特征等。</li><li>一定要做交叉验证，求平均。比赛方提供的训练集如果只用了 0.9 的数据来训练模型，那么模型很大程度会丢失剩下的 0.1 的信息，如果做了交叉验证的话，就可以兼顾到所有训练集的特征信息。</li><li>从比赛角度讲，深度学习框架 keras 是好于 TensorFlow 的，因为 keras 一般在参数调试、参数初始化以及模型搭建上面都整合的非常好；从科研角度讲，Tensorflow 具有清晰的流程，可以帮助你更好的理解深度学习的完整过程。</li><li>到了比赛后期，多模型的融合一定会有帮助，因为这样可以结合不同的模型的优缺点；模型融合最简单的方法是就是求平均，再复杂点就是对不同的模型依据效果的好坏赋予不同的权重在加权求和。</li><li>之前一直很纳闷人工设计的传统特征是怎样可以和深度学习模型相结合的，通过这次比赛，我也学习到了很多传统的NLP模型（xgboost、lightgbm、随机森林、极端随机树等），设计的特征可以加入到最后一层MLP层进行训练。</li><li>一定要有团队配合，“三个臭皮匠，顶个诸葛亮”，“1+1&gt;2”，真的真的可以从别人身上学习到很多很多的东西。</li><li>一定要多看论文、多写代码，多请教师兄、导师，“纸上得来终觉浅，绝知此事要躬行。”，“冰冻三尺，非一日之寒。”，调参经验、模型的搭建很多都是来自平时的积累、练习。</li><li>作为一个小白，一定要比别人花更多的时间和努力，才能笨鸟先飞、勤能补拙。</li><li>再忙再累也要多运动、多锻炼，身体是革命的本钱，一定要爱惜身体，督促自己，实验室固然安逸，但整天坐着身体的机能肯定会下降，发际线正在颤抖。</li><li>“路漫漫其修远兮，我将上下而求索。”</li></ul></li></ul><h3 id="五、参考文献"><a href="#五、参考文献" class="headerlink" title="五、参考文献"></a>五、参考文献</h3><ul><li>[1] Huang P S, He X, Gao J, et al. Learning deep structured semantic models for web search using clickthrough data[C]// ACM International Conference on Conference on Information &amp; Knowledge Management. ACM, 2013:2333-2338.</li><li>[2] Lan W, Xu W. Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering[J]. 2018.</li><li>[3] Wang Z, Hamza W, Florian R. Bilateral Multi-Perspective Matching for Natural Language Sentences[J]. 2017.</li><li>[4] Ghaeini R, Hasan S A, Datla V, et al. DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference[J]. 2018.</li></ul><h4 id="其他比赛选手总结"><a href="#其他比赛选手总结" class="headerlink" title="其他比赛选手总结"></a>其他比赛选手总结</h4><ul><li><a href="https://kexue.fm/archives/5743?from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://kexue.fm/archives/5743?from=timeline&amp;isappinstalled=0</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ul&gt;
&lt;li&gt;时间段：2018.06.10~2018.07.20&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&quot;问题对语义相似度计算（从0到0-5-）&quot;&gt;&lt;a href=&quot;#问题对语义相似度计算（从0到0-5-）&quot; class=&quot;headerlink&quot; title=&quot;问题对语义相似度
      
    
    </summary>
    
      <category term="总结" scheme="http://www.zhuzongkui.top/categories/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="NLP" scheme="http://www.zhuzongkui.top/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.zhuzongkui.top/2018/08/10/hexo/"/>
    <id>http://www.zhuzongkui.top/2018/08/10/hexo/</id>
    <published>2018-08-09T16:00:00.000Z</published>
    <updated>2019-09-06T10:09:24.130Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><h3 id="一条命令"><a href="#一条命令" class="headerlink" title="一条命令"></a>一条命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo clean &amp; hexo g &amp; hexo s <span class="comment"># 默认端口号：4000</span></span><br><span class="line">hexo clean &amp; hexo g &amp; hexo server -p 5000 <span class="comment"># 如果4000端口打不开，改用5000</span></span><br></pre></td></tr></table></figure><h3 id="简化命令"><a href="#简化命令" class="headerlink" title="简化命令"></a>简化命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#（1）安装 NodeJS：https://nodejs.org/en/ ，安装好后打开 git bash </span></span><br><span class="line">node -v, npm -v  <span class="comment"># 测试</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#（2）安装 hexo</span></span><br><span class="line">npm install hexo-cli -g  <span class="comment"># hexo 全局安装</span></span><br><span class="line"><span class="comment"># 若失败，配置国内镜像：https://www.jianshu.com/p/2afac1bc0af8</span></span><br><span class="line">hexo -v          <span class="comment"># 测试</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#（3）安装 hexok save</span></span><br><span class="line">npm install hexo --save</span><br><span class="line"></span><br><span class="line"><span class="comment">#（4）更新博客提交</span></span><br><span class="line">hexo c &amp; hexo g  <span class="comment"># 清理并生成</span></span><br><span class="line">hexo s -p 5000   <span class="comment"># 本地服务</span></span><br><span class="line">hexo d           <span class="comment"># 推送</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="笔记" scheme="http://www.zhuzongkui.top/categories/%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Hexo" scheme="http://www.zhuzongkui.top/tags/Hexo/"/>
    
  </entry>
  
</feed>
